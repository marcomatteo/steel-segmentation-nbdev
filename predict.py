# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/07_predict.ipynb (unless otherwise specified).

# Cell
from steel_segmentation.core import *
from steel_segmentation.data import *
from steel_segmentation.preprocessing import *
from steel_segmentation.models.dls import *
from steel_segmentation.models.metrics import *
from steel_segmentation.models.model import *

import fastai
from fastai.vision.all import *
from fastai.metrics import *
from fastai.data.all import *

import cv2
import numpy as np
import pandas as pd
from tqdm import tqdm

pred_path = path.parent / "predictions"
pred_path.mkdir(parents=True, exist_ok=True)

# Cell
# missing
arch = resnet34
bs = 4
dls = get_segmentation_dls(bs, (256, 1600))
segmentation_learner = unet_learner(dls=dls, arch=arch, metrics=seg_metrics, pretrained=True)
segmentation_learner.model_dir = models_dir
segmentation_learner = segmentation_learner.load("ResNet34-Unet-256-stage3")

# Cell
# missing
img_paths = get_image_files(test_path)
size_fold = 500
elems = len(img_paths)
folds = (elems // size_fold) + 1
threshold = 0.5
min_size = 3500
df_preds = []

# Cell
def post_process(probability, threshold, min_size):
    """
    Post processing of each predicted mask, components with lesser number of pixels
    than `min_size` are ignored
    """
    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]
    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))
    predictions = np.zeros((256, 1600), np.float32)
    num = 0
    for c in range(1, num_component):
        p = (component == c)
        if p.sum() > min_size:
            predictions[p] = 1
            num += 1
    return predictions, num

# Cell
# missing
for fold in tqdm(range(folds)):
    predictions = []

    start, end = fold*size_fold, (fold+1)*size_fold
    print(f"From {start} to {end}")
    selected_imgs = img_paths[start:end]
    # get predictions
    test_dl = segmentation_learner.dls.test_dl(test_items=selected_imgs)
    pred_probs, _, pred_masks = segmentation_learner.get_preds(dl=test_dl, with_decoded=True)
    # get img names
    img_names = L(test_dl.items).map(lambda x: x.name)
    # calc the RLEs
    for num_pred, t_pred in enumerate(pred_probs): # img in bs
        np_pred = t_pred.numpy()
        # iterate through class_id without class_id 0
        for class_id, prob in enumerate(np_pred[1:]):
            pred, num = post_process(prob, threshold, min_size)
            rle = mask2rle(pred)
            name = img_names[num_pred] + f"_{class_id+1}"
            predictions.append([name, rle])

    tmp_df = pd.DataFrame(predictions, columns=['ImageId_ClassId', 'EncodedPixels'])
    df_preds.append(tmp_df)

    torch.cuda.empty_cache()
    del predictions

# Cell
# missing
df = pd.concat(tmp_df, axis=0, ignore_index=True)
df.fillna("", inplace=True)
df.to_csv(path/"submission.csv", index=False)
