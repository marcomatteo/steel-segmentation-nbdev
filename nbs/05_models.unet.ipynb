{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "declared-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.unet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hundred-theology",
   "metadata": {},
   "source": [
    "# Unet Architecture\n",
    "\n",
    "> A deep dive into Unet architecture in Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uniform-above",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-doubt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "naughty-cream",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "import graphviz\n",
    "def gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"' + s + '; }')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-preserve",
   "metadata": {},
   "source": [
    "Unet architecture from the [segmentation_models.pytorch](https://github.com/qubvel/segmentation_models.pytorch) repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-attempt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "import functools\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torchvision.models.resnet import ResNet\n",
    "from torchvision.models.resnet import BasicBlock\n",
    "from torchvision.models.resnet import Bottleneck\n",
    "from pretrainedmodels.models.torchvision_models import pretrained_settings\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-enforcement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def initialize(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(\n",
    "                    m.weight, mode='fan_out', nonlinearity='relu')\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designed-welcome",
   "metadata": {},
   "source": [
    "Custom `nn.Module` class with `kaiming_normal_` initialization. This class look into `self.modules` and if it's a `nn.BatchNorm2d` init with 1 the weights and 0 the biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lightweight-draft",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Conv2dReLU(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0,\n",
    "                 stride=1, use_batchnorm=True, **batchnorm_params):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size,\n",
    "                      stride=stride, padding=padding, bias=not (use_batchnorm)),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "\n",
    "        if use_batchnorm:\n",
    "            layers.insert(1, nn.BatchNorm2d(out_channels, **batchnorm_params))\n",
    "\n",
    "        self.block = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-server",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Conv2dReLU.__init__\" class=\"doc_header\"><code>Conv2dReLU.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Conv2dReLU.__init__</code>(**`in_channels`**, **`out_channels`**, **`kernel_size`**, **`padding`**=*`0`*, **`stride`**=*`1`*, **`use_batchnorm`**=*`True`*, **\\*\\*`batchnorm_params`**)\n",
       "\n",
       "Initializes internal Module state, shared by both nn.Module and ScriptModule."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show_doc(Conv2dReLU.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-mandate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: G Pages: 1 -->\n",
       "<svg width=\"332pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 332.18 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-40 328.1776,-40 328.1776,4 -4,4\"/>\n",
       "<!-- Conv2d -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>Conv2d</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"39.6465\" cy=\"-18\" rx=\"39.7935\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"39.6465\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">Conv2d</text>\n",
       "</g>\n",
       "<!-- BatchNorm -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>BatchNorm</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"168.5882\" cy=\"-18\" rx=\"53.0913\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"168.5882\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">BatchNorm</text>\n",
       "</g>\n",
       "<!-- Conv2d&#45;&gt;BatchNorm -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>Conv2d&#45;&gt;BatchNorm</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M79.3854,-18C87.4695,-18 96.1651,-18 104.8432,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"104.9848,-21.5001 114.9847,-18 104.9847,-14.5001 104.9848,-21.5001\"/>\n",
       "</g>\n",
       "<!-- ReLU -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>ReLU</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"291.0306\" cy=\"-18\" rx=\"33.2948\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"291.0306\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">ReLU</text>\n",
       "</g>\n",
       "<!-- BatchNorm&#45;&gt;ReLU -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>BatchNorm&#45;&gt;ReLU</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M221.937,-18C230.4558,-18 239.1814,-18 247.4391,-18\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"247.598,-21.5001 257.5979,-18 247.5979,-14.5001 247.598,-21.5001\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x7f937c6a66d0>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gv('''Conv2d->BatchNorm->ReLU''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banned-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, use_batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            Conv2dReLU(in_channels, out_channels, kernel_size=3,\n",
    "                       padding=1, use_batchnorm=use_batchnorm),\n",
    "            Conv2dReLU(out_channels, out_channels, kernel_size=3,\n",
    "                       padding=1, use_batchnorm=use_batchnorm),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x, skip = x\n",
    "        x = F.interpolate(x, scale_factor=2, mode='nearest')\n",
    "        if skip is not None:\n",
    "            x = torch.cat([x, skip], dim=1)\n",
    "        x = self.block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "single-symphony",
   "metadata": {},
   "source": [
    "Up sample the inputs by a `scale_factor` of 2 with `'nearest'`, if a `skip` connection is provided then concatenates with the inputs and then do a double `Conv2dReLU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chronic-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class CenterBlock(DecoderBlock):\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "happy-stadium",
   "metadata": {},
   "source": [
    "A double `Conv2dReLU` without up sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EncoderDecoder(Model):\n",
    "\n",
    "    def __init__(self, encoder, decoder, activation):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "        if callable(activation) or activation is None:\n",
    "            self.activation = activation\n",
    "        elif activation == 'softmax':\n",
    "            self.activation = nn.Softmax(dim=1)\n",
    "        elif activation == 'sigmoid':\n",
    "            self.activation = nn.Sigmoid()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Activation should be \"sigmoid\"/\"softmax\"/callable/None')\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Sequentially pass `x` trough model's `encoder` and `decoder` (return logits!)\"\"\"\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "    def predict(self, x):\n",
    "        \"\"\"\n",
    "        Inference method. Switch model to `eval` mode, call `.forward(x)`\n",
    "        and apply activation function (if activation is not `None`) with `torch.no_grad()`\n",
    "\n",
    "        Args:\n",
    "            x: 4D torch tensor with shape (batch_size, channels, height, width)\n",
    "\n",
    "        Return:\n",
    "            prediction: 4D torch tensor with shape (batch_size, classes, height, width)\n",
    "\n",
    "        \"\"\"\n",
    "        if self.training:\n",
    "            self.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            x = self.forward(x)\n",
    "            if self.activation:\n",
    "                x = self.activation(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atomic-crystal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EncoderDecoder.__init__\" class=\"doc_header\"><code>EncoderDecoder.__init__</code><a href=\"__main__.py#L4\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EncoderDecoder.__init__</code>(**`encoder`**, **`decoder`**, **`activation`**)\n",
       "\n",
       "Initializes internal Module state, shared by both nn.Module and ScriptModule."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show_doc(EncoderDecoder.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-nudist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EncoderDecoder.forward\" class=\"doc_header\"><code>EncoderDecoder.forward</code><a href=\"__main__.py#L19\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EncoderDecoder.forward</code>(**`x`**)\n",
       "\n",
       "Sequentially pass `x` trough model's `encoder` and `decoder` (return logits!)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show_doc(EncoderDecoder.forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protecting-lecture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"EncoderDecoder.predict\" class=\"doc_header\"><code>EncoderDecoder.predict</code><a href=\"__main__.py#L25\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>EncoderDecoder.predict</code>(**`x`**)\n",
       "\n",
       "Inference method. Switch model to `eval` mode, call `.forward(x)`\n",
       "and apply activation function (if activation is not `None`) with `torch.no_grad()`\n",
       "\n",
       "Args:\n",
       "    x: 4D torch tensor with shape (batch_size, channels, height, width)\n",
       "\n",
       "Return:\n",
       "    prediction: 4D torch tensor with shape (batch_size, classes, height, width)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show_doc(EncoderDecoder.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-harbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class UnetDecoder(Model):\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            encoder_channels,\n",
    "            decoder_channels=(256, 128, 64, 32, 16),\n",
    "            final_channels=1,\n",
    "            use_batchnorm=True,\n",
    "            center=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if center:\n",
    "            channels = encoder_channels[0]\n",
    "            self.center = CenterBlock(\n",
    "                channels, channels, use_batchnorm=use_batchnorm)\n",
    "        else:\n",
    "            self.center = None\n",
    "\n",
    "        in_channels = self.compute_channels(encoder_channels, decoder_channels)\n",
    "        out_channels = decoder_channels\n",
    "\n",
    "        self.layer1 = DecoderBlock(\n",
    "            in_channels[0], out_channels[0], use_batchnorm=use_batchnorm)\n",
    "        self.layer2 = DecoderBlock(\n",
    "            in_channels[1], out_channels[1], use_batchnorm=use_batchnorm)\n",
    "        self.layer3 = DecoderBlock(\n",
    "            in_channels[2], out_channels[2], use_batchnorm=use_batchnorm)\n",
    "        self.layer4 = DecoderBlock(\n",
    "            in_channels[3], out_channels[3], use_batchnorm=use_batchnorm)\n",
    "        self.layer5 = DecoderBlock(\n",
    "            in_channels[4], out_channels[4], use_batchnorm=use_batchnorm)\n",
    "        self.final_conv = nn.Conv2d(\n",
    "            out_channels[4], final_channels, kernel_size=(1, 1))\n",
    "\n",
    "        self.initialize()\n",
    "\n",
    "    def compute_channels(self, encoder_channels, decoder_channels):\n",
    "        channels = [\n",
    "            encoder_channels[0] + encoder_channels[1],\n",
    "            encoder_channels[2] + decoder_channels[0],\n",
    "            encoder_channels[3] + decoder_channels[1],\n",
    "            encoder_channels[4] + decoder_channels[2],\n",
    "            0 + decoder_channels[3],\n",
    "        ]\n",
    "        return channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_head = x[0]\n",
    "        skips = x[1:]\n",
    "\n",
    "        if self.center:\n",
    "            encoder_head = self.center(encoder_head)\n",
    "\n",
    "        x = self.layer1([encoder_head, skips[0]])\n",
    "        x = self.layer2([x, skips[1]])\n",
    "        x = self.layer3([x, skips[2]])\n",
    "        x = self.layer4([x, skips[3]])\n",
    "        x = self.layer5([x, None])\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-riding",
   "metadata": {},
   "source": [
    "Decoder part of a Unet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ResNetEncoder(ResNet):\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.pretrained = False\n",
    "        del self.fc\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0 = self.conv1(x)\n",
    "        x0 = self.bn1(x0)\n",
    "        x0 = self.relu(x0)\n",
    "\n",
    "        x1 = self.maxpool(x0)\n",
    "        x1 = self.layer1(x1)\n",
    "\n",
    "        x2 = self.layer2(x1)\n",
    "        x3 = self.layer3(x2)\n",
    "        x4 = self.layer4(x3)\n",
    "\n",
    "        return [x4, x3, x2, x1, x0]\n",
    "\n",
    "    def load_state_dict(self, state_dict, **kwargs):\n",
    "        state_dict.pop('fc.bias')\n",
    "        state_dict.pop('fc.weight')\n",
    "        super().load_state_dict(state_dict, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modular-major",
   "metadata": {},
   "source": [
    "Encoder part of a Unet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proved-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "resnet_encoders = {\n",
    "    'resnet18': {\n",
    "        'encoder': ResNetEncoder,\n",
    "        'pretrained_settings': pretrained_settings['resnet18'],\n",
    "        'out_shapes': (512, 256, 128, 64, 64),\n",
    "        'params': {\n",
    "            'block': BasicBlock,\n",
    "            'layers': [2, 2, 2, 2],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'resnet34': {\n",
    "        'encoder': ResNetEncoder,\n",
    "        'pretrained_settings': pretrained_settings['resnet34'],\n",
    "        'out_shapes': (512, 256, 128, 64, 64),\n",
    "        'params': {\n",
    "            'block': BasicBlock,\n",
    "            'layers': [3, 4, 6, 3],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'resnet50': {\n",
    "        'encoder': ResNetEncoder,\n",
    "        'pretrained_settings': pretrained_settings['resnet50'],\n",
    "        'out_shapes': (2048, 1024, 512, 256, 64),\n",
    "        'params': {\n",
    "            'block': Bottleneck,\n",
    "            'layers': [3, 4, 6, 3],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'resnet101': {\n",
    "        'encoder': ResNetEncoder,\n",
    "        'pretrained_settings': pretrained_settings['resnet101'],\n",
    "        'out_shapes': (2048, 1024, 512, 256, 64),\n",
    "        'params': {\n",
    "            'block': Bottleneck,\n",
    "            'layers': [3, 4, 23, 3],\n",
    "        },\n",
    "    },\n",
    "\n",
    "    'resnet152': {\n",
    "        'encoder': ResNetEncoder,\n",
    "        'pretrained_settings': pretrained_settings['resnet152'],\n",
    "        'out_shapes': (2048, 1024, 512, 256, 64),\n",
    "        'params': {\n",
    "            'block': Bottleneck,\n",
    "            'layers': [3, 8, 36, 3],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "encoders = {}\n",
    "encoders.update(resnet_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "manual-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def preprocess_input(x, mean=None, std=None, input_space='RGB', input_range=None, **kwargs):\n",
    "    \"\"\"Preprocessing the `x` inputs with normalization.\"\"\"\n",
    "    if input_space == 'BGR':\n",
    "        x = x[..., ::-1].copy()\n",
    "\n",
    "    if input_range is not None:\n",
    "        if x.max() > 1 and input_range[1] == 1:\n",
    "            x = x / 255.\n",
    "\n",
    "    if mean is not None:\n",
    "        mean = np.array(mean)\n",
    "        x = x - mean\n",
    "\n",
    "    if std is not None:\n",
    "        std = np.array(std)\n",
    "        x = x / std\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hispanic-palestinian",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_encoder(name, encoder_weights=None):\n",
    "    Encoder = encoders[name]['encoder']\n",
    "    encoder = Encoder(**encoders[name]['params'])\n",
    "    encoder.out_shapes = encoders[name]['out_shapes']\n",
    "\n",
    "    if encoder_weights is not None:\n",
    "        settings = encoders[name]['pretrained_settings'][encoder_weights]\n",
    "        encoder.load_state_dict(model_zoo.load_url(settings['url']))\n",
    "\n",
    "    return encoder\n",
    "\n",
    "\n",
    "def get_encoder_names():\n",
    "    return list(encoders.keys())\n",
    "\n",
    "\n",
    "def get_preprocessing_fn(encoder_name, pretrained='imagenet'):\n",
    "    settings = encoders[encoder_name]['pretrained_settings']\n",
    "\n",
    "    if pretrained not in settings.keys():\n",
    "        raise ValueError(\n",
    "            'Avaliable pretrained options {}'.format(settings.keys()))\n",
    "\n",
    "    input_space = settings[pretrained].get('input_space')\n",
    "    input_range = settings[pretrained].get('input_range')\n",
    "    mean = settings[pretrained].get('mean')\n",
    "    std = settings[pretrained].get('std')\n",
    "\n",
    "    return functools.partial(preprocess_input, mean=mean, std=std, input_space=input_space, input_range=input_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enhanced-dispatch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Unet(EncoderDecoder):\n",
    "    \"\"\"Unet_ is a fully convolution neural network for image semantic segmentation\n",
    "\n",
    "    Args:\n",
    "        encoder_name: name of classification model (without last dense layers) used as feature\n",
    "            extractor to build segmentation model.\n",
    "        encoder_weights: one of ``None`` (random initialization), ``imagenet`` (pre-training on ImageNet).\n",
    "        decoder_channels: list of numbers of ``Conv2D`` layer filters in decoder blocks\n",
    "        decoder_use_batchnorm: if ``True``, ``BatchNormalisation`` layer between ``Conv2D`` and ``Activation`` layers\n",
    "            is used.\n",
    "        classes: a number of classes for output (output shape - ``(batch, classes, h, w)``).\n",
    "        activation: activation function used in ``.predict(x)`` method for inference.\n",
    "            One of [``sigmoid``, ``softmax``, callable, None]\n",
    "        center: if ``True`` add ``Conv2dReLU`` block on encoder head (useful for VGG models)\n",
    "\n",
    "    Returns:\n",
    "        ``torch.nn.Module``: **Unet**\n",
    "\n",
    "    Paper:\n",
    "    https://arxiv.org/pdf/1505.04597\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "            encoder_name='resnet34',\n",
    "            encoder_weights='imagenet',\n",
    "            decoder_use_batchnorm=True,\n",
    "            decoder_channels=(256, 128, 64, 32, 16),\n",
    "            classes=1,\n",
    "            activation='sigmoid',\n",
    "            center=False,  # usefull for VGG models\n",
    "    ):\n",
    "        encoder = get_encoder(\n",
    "            encoder_name,\n",
    "            encoder_weights=encoder_weights\n",
    "        )\n",
    "\n",
    "        decoder = UnetDecoder(\n",
    "            encoder_channels=encoder.out_shapes,\n",
    "            decoder_channels=decoder_channels,\n",
    "            final_channels=classes,\n",
    "            use_batchnorm=decoder_use_batchnorm,\n",
    "            center=center,\n",
    "        )\n",
    "\n",
    "        super().__init__(encoder, decoder, activation)\n",
    "\n",
    "        self.name = 'u-{}'.format(encoder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpine-indonesia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Unet.__init__\" class=\"doc_header\"><code>Unet.__init__</code><a href=\"__main__.py#L25\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Unet.__init__</code>(**`encoder_name`**=*`'resnet34'`*, **`encoder_weights`**=*`'imagenet'`*, **`decoder_use_batchnorm`**=*`True`*, **`decoder_channels`**=*`(256, 128, 64, 32, 16)`*, **`classes`**=*`1`*, **`activation`**=*`'sigmoid'`*, **`center`**=*`False`*)\n",
       "\n",
       "Initializes internal Module state, shared by both nn.Module and ScriptModule."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show_doc(Unet.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-recycling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_models.dls.ipynb.\n",
      "Converted 04_model.metrics.ipynb.\n",
      "Converted 05_models.unet.ipynb.\n",
      "Converted 06_models.model.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
