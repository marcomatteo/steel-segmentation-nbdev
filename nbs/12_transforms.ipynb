{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# default_exp transforms\n",
    "# all_slow"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# hide\n",
    "! [ -e /content ] && pip install -Uqq fastai  # upgrade fastai on colab\n",
    "! [ -e /content ] && pip install -Uqq albumentations  # upgrade albumentations"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# hide\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "os.chdir(\"/content/drive/MyDrive/Colab Notebooks/severstal\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Transforms\n",
    "\n",
    "> Fastai Transforms API to Severstal dataset."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "# export\n",
    "from fastai.vision.all import *\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from steel_segmentation.utils import rle2mask, mask2rle"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# export\n",
    "class ReadImagePathFromIndex(Transform):\n",
    "    \"\"\"Read image name from `train_pivot` and returns the image path\"\"\"\n",
    "    def __init__(self, pref):\n",
    "        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref\n",
    "\n",
    "    def encodes(self, row:pd.Series, **kwargs):\n",
    "        o = row.name # ImageId\n",
    "        return f'{self.pref}{o}'     "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# export\n",
    "class ReadRLEs(Transform):\n",
    "    \"\"\"Read RLEs from `train_pivot` and return a list or RLEs.\"\"\"\n",
    "    def __init__(self, cols=[1,2,3,4]):\n",
    "        self.cols = L(cols)\n",
    "\n",
    "    def encodes(self, row:pd.Series, **kwargs):\n",
    "        return [row[i] if not row[i] is np.nan else ''\n",
    "                for i in self.cols]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# export\n",
    "class MakeMask(Transform):\n",
    "    \"\"\"Read RLEs list and return a np.array of the mask\"\"\"\n",
    "    h, w = (256, 1600)\n",
    "\n",
    "    def __init__(self, flatten=True):\n",
    "        self.flatten = flatten\n",
    "\n",
    "    def encodes(self, o:list, **kwargs):\n",
    "        mask = np.zeros((self.h, self.w, 4), dtype=np.float32) # 4:class 1～4 (ch:0～3)\n",
    "\n",
    "        for i in range(4):\n",
    "            rle = o[i]\n",
    "            if rle != '':\n",
    "                mask[:, :, i] = rle2mask(rle=rle, value=1, shape=(self.h,self.w))\n",
    "\n",
    "        if self.flatten:\n",
    "            classes = np.array(range(1,5))\n",
    "            return (mask * classes).sum(-1)\n",
    "\n",
    "        return mask\n",
    "\n",
    "    def decodes(self, mask, **kwargs):\n",
    "        mask = (mask * np.array(range(1,5))).sum(-1) if len(mask.shape) == 3 else mask\n",
    "        return [mask2rle(np.where(mask==c, mask, 0)) for c in range(1,5)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# export\n",
    "class ChannelMask(Transform):\n",
    "    \"\"\"Transform (x,y) tensor masks from [w, h] to [channels, w, h]\"\"\"\n",
    "    order=9\n",
    "\n",
    "    def create_mask(self, mask):\n",
    "        new_mask = torch.zeros(4, mask.shape[0], mask.shape[1])\n",
    "        for i in range(4):\n",
    "            new_mask[i] = torch.where(mask==(i+1), 1, 0)\n",
    "        return new_mask\n",
    "\n",
    "    def decode_mask(self, mask, classes):\n",
    "        # tensorboard log images bug in TensorBoardCallback after_epoch\n",
    "        if mask.device != classes.device:\n",
    "            mask = mask.to(classes.device)\n",
    "        return (mask * classes).sum(0)\n",
    "\n",
    "    def encodes(self, o:TensorMask):\n",
    "        if o.dim() == 2: return self.create_mask(o)\n",
    "        elif o.dim() == 3:\n",
    "            new_batch = []\n",
    "            for mask in o: new_batch.append(self.create_mask(mask))\n",
    "            return torch.stack(new_batch, axis=0)\n",
    "        else: return o\n",
    "\n",
    "    def decodes(self, o:TensorMask):\n",
    "        classes = torch.tensor(range(1,5)).unsqueeze(-1).unsqueeze(-1)\n",
    "        if o.dim() == 3: return self.decode_mask(o, classes)\n",
    "        elif o.dim() == 4:\n",
    "            new_masks = []\n",
    "            for mask in o:\n",
    "                new_masks.append(self.decode_mask(mask, classes))\n",
    "            return torch.stack(new_masks, axis=0)\n",
    "        else: return o"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "# export\n",
    "class AlbumentationsTransform(ItemTransform, RandTransform):\n",
    "    \"A transform handler for multiple `Albumentation` transforms\"\n",
    "    split_idx,order=None,2\n",
    "    def __init__(self, train_aug, valid_aug): \n",
    "        self.train_aug, self.valid_aug = train_aug, valid_aug\n",
    "\n",
    "    def before_call(self, b, split_idx):\n",
    "        self.idx = split_idx\n",
    "\n",
    "    def encodes(self, o):\n",
    "        img, mask = o\n",
    "        if self.idx == 0:\n",
    "            aug = self.train_aug(image=np.array(img),mask=np.array(mask))\n",
    "            aug_img = aug['image']\n",
    "            aug_mask = aug['mask']\n",
    "        else:\n",
    "            aug = self.valid_aug(image=np.array(img),mask=np.array(mask))\n",
    "            aug_img = aug['image']\n",
    "            aug_mask = aug['mask']\n",
    "        return PILImage.create(aug_img), PILMask.create(aug_mask)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# export\n",
    "def SteelMaskBlock():\n",
    "    tfm_mask = MakeMask()\n",
    "    tfm_addCodes = AddMaskCodes([1,2,3,4])\n",
    "    tfm_block = TransformBlock(\n",
    "        type_tfms=[tfm_mask, PILMask.create],\n",
    "        item_tfms=[tfm_addCodes]\n",
    "    )\n",
    "    return tfm_block"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Converted 01_metadata.ipynb.\n",
      "Converted 02_masks.ipynb.\n",
      "Converted 03_datasets.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_loss.ipynb.\n",
      "Converted 07_trainer.ipynb.\n",
      "Converted 08_predict.ipynb.\n",
      "Converted 11_eda.ipynb.\n",
      "Converted 12_transforms.ipynb.\n",
      "Converted 13_dataset.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}