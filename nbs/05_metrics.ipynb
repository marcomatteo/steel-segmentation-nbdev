{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#missing\n",
    "#!git clone https://github.com/marcomatteo/steel_segmentation.git\n",
    "#!pip install -e steel_segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastai --upgrade\n",
    "!pip install -Uqq fastcore --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> A collection of Metrics used in the segmentation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcomatteo/steel_segmentation/blob/master/nbs/05_metrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from steel_segmentation.metadata import *\n",
    "from steel_segmentation.masks import *\n",
    "from steel_segmentation.datasets import *\n",
    "from steel_segmentation.dataloaders import *\n",
    "\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastcore.foundation import *\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section there are all the metric that can be used to evaluate the performances of the segmentation models trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 3, 256, 1600]), torch.Size([20, 4, 256, 1600]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "dls = get_segmnt_dls(train_pivot, bs=20)\n",
    "x, targs = dls.train.one_batch()\n",
    "x.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "x = x.cpu()\n",
    "model = smp.Unet(\"resnet34\", \n",
    "                 encoder_weights=\"imagenet\", \n",
    "                 classes=4, \n",
    "                 activation=None)\n",
    "loaded_params = torch.load(models_dir/\"kaggle-UNET-ResNet34.pth\")\n",
    "model.load_state_dict(loaded_params[\"state_dict\"], strict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing\n",
    "logits = model(x)\n",
    "probs = torch.sigmoid(logits) \n",
    "preds = (probs > 0.5).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simulated training with `compute_val` and a test Learner with `TstLearner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For testing: a fake learner and a metric that isn't an average\n",
    "@delegates()\n",
    "class TstLearner(Learner):\n",
    "    def __init__(self,dls=None,model=None,**kwargs): \n",
    "        self.pred,self.xb,self.yb = None,None,None\n",
    "        self.loss_func=BCEWithLogitsLossFlat()\n",
    "        \n",
    "#Go through a fake cycle with various batch sizes and computes the value of met\n",
    "def compute_val(met, pred, y):\n",
    "    met.reset()\n",
    "    vals = [0,6,15,20]\n",
    "    learn = TstLearner()\n",
    "    for i in range(3):\n",
    "        learn.pred = pred[vals[i]:vals[i+1]]\n",
    "        learn.yb = ( y[vals[i]:vals[i+1]], )\n",
    "        met.accumulate(learn)\n",
    "    return met.value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fastai` library comes with a dice metric for multiple channel masks. As a segmentation metric in this frameworks, it expects a flatten mask for targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multidice_obj = DiceMulti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5713036010962022"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "compute_val(multidice_obj, pred=preds, y=targs.argmax(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we slightly change the `DiceMulti` for a 4-channel mask as targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModDiceMulti(Metric):\n",
    "    \"Averaged Dice metric (Macro F1) for multiclass target in segmentation\"\n",
    "\n",
    "    def __init__(self, axis=1, with_logits=False): \n",
    "        self.axis = axis\n",
    "        self.with_logits = with_logits\n",
    "        \n",
    "    def reset(self): self.inter, self.union =  {}, {}\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        if self.with_logits:\n",
    "            logit = learn.pred\n",
    "            prob = torch.sigmoid(logit)\n",
    "            pred = (prob > 0.5).float().argmax(dim=self.axis)\n",
    "        else:\n",
    "            pred = learn.pred.argmax(dim=self.axis)\n",
    "        \n",
    "        y = learn.yb[0]\n",
    "        # Added to deal with 4-channels masks\n",
    "        if pred.shape != y.shape:\n",
    "            y = y.argmax(dim=self.axis)\n",
    "            \n",
    "        pred, targ = flatten_check(pred, y)\n",
    "        for c in range(learn.pred.shape[self.axis]):\n",
    "            p = torch.where(pred == c, 1, 0)\n",
    "            t = torch.where(targ == c, 1, 0)\n",
    "            p, t = TensorBase(p), TensorBase(t) # may be redundant (old fastai bug)\n",
    "            c_inter = (p*t).float().sum().item()\n",
    "            c_union = (p+t).float().sum().item()\n",
    "            if c in self.inter:\n",
    "                self.inter[c] += c_inter\n",
    "                self.union[c] += c_union\n",
    "            else:\n",
    "                self.inter[c] = c_inter\n",
    "                self.union[c] = c_union\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        binary_dice_scores = np.array([])\n",
    "        for c in self.inter:\n",
    "            binary_dice_scores = np.append(\n",
    "                binary_dice_scores, \n",
    "                2.*self.inter[c]/self.union[c] if self.union[c] > 0 else np.nan)\n",
    "        self.binary_dice_scores = binary_dice_scores\n",
    "        return np.nanmean(binary_dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_obj = ModDiceMulti(with_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5713036010962022"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "compute_val(dice_obj, pred=logits, y=targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_obj = ModDiceMulti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5713036010962022"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "compute_val(dice_obj, pred=preds, y=targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different targets: \n",
    "- a flatten mask, used by fastai segmentation models\n",
    "- a 4-channels mask, used by pytorch segmentation models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1a = torch.ones(20,1,1,1)\n",
    "x1b = torch.clone(x1a)*0.5\n",
    "x1c = torch.clone(x1a)*0.3\n",
    "x1d = torch.clone(x1a)*0.1\n",
    "x1 = torch.cat((x1a,x1b,x1c,x1d),dim=1)   # Prediction: 20x4\n",
    "\n",
    "x2 = torch.zeros(20,1,1)       # Target: 20xClass0\n",
    "x2chs = torch.zeros(20,4,1,1)  # Target: 20xClass0\n",
    "\n",
    "# Dice metric = 1\n",
    "test_eq(compute_val(dice_obj, x1, x2), 1.)\n",
    "test_eq(compute_val(dice_obj, x1, x2chs), 1.)\n",
    "\n",
    "x2_ch0 = torch.zeros(20,1,1,1)\n",
    "x2_ch1 = torch.ones(20,1,1,1)\n",
    "x2_ch2 = torch.zeros(20,1,1,1)\n",
    "x2_ch3 = torch.zeros(20,1,1,1)\n",
    "x2_chs = (x2_ch0, x2_ch1, x2_ch2, x2_ch3)\n",
    "\n",
    "x2 = torch.ones(20,1,1)          # Target: 20xClass1\n",
    "x2chs = torch.cat(x2_chs, dim=1) # Target: 20xClass1\n",
    "\n",
    "# Dice metric = 0\n",
    "test_eq(compute_val(dice_obj, x1, x2), 0.)\n",
    "test_eq(compute_val(dice_obj, x1, x2chs), 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different scenario with a multiclass batch:\n",
    "- Class0 x 10\n",
    "- Class1 x 4\n",
    "- Class2 x 3\n",
    "- Class4 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target: 10xClass0, 4xClass1, 3xClass2, 3xClass4\n",
    "x2a = torch.zeros(10,1,1)\n",
    "x2b = torch.ones(4,1,1)\n",
    "x2c = torch.ones(3,1,1) * 2\n",
    "x2d = torch.ones(3,1,1) * 3\n",
    "x2 = torch.cat((x2a,x2b,x2c,x2d),dim=0) # shape (20, 1, 1)\n",
    "computed_dice = compute_val(dice_obj, x1, x2)\n",
    "\n",
    "batch_sizes = [10, 4, 3, 3]\n",
    "x2_chs = [torch.zeros(n, 4, 1, 1) for i, n in enumerate(batch_sizes)]\n",
    "for i, x2_ch in enumerate(x2_chs):\n",
    "    x2_ch[:, i] = 1\n",
    "x2chs = torch.cat(x2_chs, dim=0) # shape (20, 4, 1, 1)\n",
    "computed_dice_chs = compute_val(dice_obj, x1, x2chs)\n",
    "\n",
    "# Dice: 2*TP/(2*TP+FP+FN)\n",
    "dice1 = (2*10)/(2*10+4+3+3)              \n",
    "dice2 = 0\n",
    "dice3 = 0\n",
    "dice4 = 0\n",
    "\n",
    "# Dice metric = 0.1666\n",
    "test_eq(computed_dice,     (dice1+dice2+dice3+dice4)/4)\n",
    "test_eq(computed_dice_chs, (dice1+dice2+dice3+dice4)/4)\n",
    "test_eq(computed_dice, computed_dice_chs)\n",
    "\n",
    "computed_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dice metric\n",
    "The competition [evaluation metric](https://www.kaggle.com/c/severstal-steel-defect-detection/overview/evaluation) is defined as:\n",
    "\n",
    "> This competition is evaluated on the mean Dice coefficient. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:\n",
    "\n",
    "$$\n",
    "J(A,B) = \\frac{2 * |A \\cap B|}{|A| \\cup |B|}\n",
    "$$\n",
    "\n",
    "> where X is the predicted set of pixels and Y is the ground truth. The Dice coefficient is defined to be 1 when both X and Y are empty. The leaderboard score is the mean of the Dice coefficients for each <ImageId, ClassId> pair in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class KaggleDice(Metric):\n",
    "    \"\"\"\n",
    "    Multi-class Dice used in Severstal comp,\n",
    "    is 1 when prediction and mask are empty\n",
    "    \"\"\"\n",
    "    def __init__(self, axis=1, with_logits=False, eps=1e-9): \n",
    "        self.axis = axis\n",
    "        self.eps = eps\n",
    "        self.with_logits = with_logits\n",
    "        \n",
    "    def reset(self): self.inter, self.union = defaultdict(list), defaultdict(list)\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        if self.with_logits:\n",
    "            logit = learn.pred\n",
    "            prob = torch.sigmoid(logit)\n",
    "            pred = (prob > 0.5).float().argmax(dim=self.axis)\n",
    "        else:\n",
    "            pred = learn.pred.argmax(dim=self.axis)\n",
    "        \n",
    "        y = learn.yb[0]\n",
    "        if pred.shape != y.shape:\n",
    "            y = y.argmax(dim=self.axis)\n",
    "        \n",
    "        n, c = y.shape[0], pred.shape[self.axis]\n",
    "            \n",
    "        preds, targs = flatten_check(pred, y)\n",
    "        for i in range(0, c):\n",
    "            p = torch.where(preds == i, 1, 0)\n",
    "            t = torch.where(targs == i, 1, 0)\n",
    "\n",
    "            p, t = TensorBase(p), TensorBase(t)\n",
    "\n",
    "            c_inter = (p*t).sum(-1).float()#.item()\n",
    "            c_union = (p+t).sum(-1).float()#.item()\n",
    "\n",
    "            self.inter[i].append(c_inter) \n",
    "            self.union[i].append(c_union)\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        binary_dice_scores = np.array([])\n",
    "        for c in range(len(self.inter)):\n",
    "            inter = torch.stack(self.inter[c])\n",
    "            union = torch.stack(self.union[c])\n",
    "            \n",
    "            val = 2.*(inter+self.eps)/(union+self.eps)\n",
    "            cond = union == 0\n",
    "            val[cond] = 1\n",
    "            \n",
    "            binary_dice_scores = np.append(binary_dice_scores, val.cpu().numpy())\n",
    "            \n",
    "        self.binary_dice_scores = binary_dice_scores\n",
    "        return np.nanmean(binary_dice_scores)        \n",
    "        #return (binary_dice_scores).reshape(-1, 4).mean(0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_kobj = KaggleDice(with_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9962328915329041"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "compute_val(dice_kobj, pred=logits, y=targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_kobj = KaggleDice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9962328915329041"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "compute_val(dice_kobj, pred=preds, y=targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to cast a metric founded in a Kaggle discussion. These metrics work but can be problematic with a valuation phase with more than 1000 examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def single_dice_coef(y_true, y_pred, smooth=1):\n",
    "    \"\"\"Binary segmentation function.\"\"\"\n",
    "    y_true_f = np.ndarray.flatten(y_true)\n",
    "    y_pred_f = np.ndarray.flatten(y_pred)\n",
    "    intersection = np.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)\n",
    "\n",
    "def single_dice_coef_channel(y_true, y_pred, smooth=1):\n",
    "    \"\"\"Multichannel segmentation function.\"\"\"\n",
    "    ch1 = single_dice_coef(y_true[:,0,:,:], y_pred[:,0,:,:],smooth)\n",
    "    ch2 = single_dice_coef(y_true[:,1,:,:], y_pred[:,1,:,:],smooth)\n",
    "    ch3 = single_dice_coef(y_true[:,2,:,:], y_pred[:,2,:,:],smooth)\n",
    "    ch4 = single_dice_coef(y_true[:,3,:,:], y_pred[:,3,:,:],smooth)\n",
    "    res = (ch1+ch2+ch3+ch4)/4\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "KaggleDiceCoefMulti = AccumMetric(single_dice_coef_channel, to_np=True, flatten=False, thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5636921149524751"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "compute_val(KaggleDiceCoefMulti, logits, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "FastKaggleCoefDiceMulti = AccumMetric(single_dice_coef_channel, to_np=True, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = torch.zeros(20, 4, 1, 1), torch.zeros(20, 4, 1, 1)\n",
    "\n",
    "test_eq(compute_val(FastKaggleCoefDiceMulti, x0, y0), 1.)\n",
    "test_close(compute_val(FastKaggleCoefDiceMulti, x1, x2chs), 0.38935)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5962340563656034"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "compute_val(FastKaggleCoefDiceMulti, preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "KaggleDiceCoef = AccumMetric(single_dice_coef, to_np=True, flatten=False, thresh=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.556828003457217\n",
      "1.0\n",
      "0.6978286745507603\n",
      "0.000111781801922647\n"
     ]
    }
   ],
   "source": [
    "#missing\n",
    "for ch in range(4):\n",
    "    print(compute_val(KaggleDiceCoef, logits[:,ch], targs[:,ch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exports\n",
    "FastKaggleDiceCoef = AccumMetric(single_dice_coef, to_np=True, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6492999628298848\n",
      "1.0\n",
      "0.7355494646115235\n",
      "8.679802100512108e-05\n"
     ]
    }
   ],
   "source": [
    "#missing\n",
    "for ch in range(4):\n",
    "    print(compute_val(FastKaggleDiceCoef, preds[:,ch], targs[:,ch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = torch.zeros(20, 1, 1), torch.zeros(20, 1, 1)\n",
    "test_eq(compute_val(FastKaggleDiceCoef, x0, y0), 1.)\n",
    "test_eq(compute_val(FastKaggleDiceCoef, x1[:,0], x2), 0.975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_metadata.ipynb.\n",
      "Converted 02_masks.ipynb.\n",
      "Converted 03_datasets.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_loss.ipynb.\n",
      "Converted 07_trainer.ipynb.\n",
      "Converted 08_predict.ipynb.\n",
      "Converted 09_visualize.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}