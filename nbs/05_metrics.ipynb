{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# missing\n",
    "!git clone https://github.com/marcomatteo/steel_segmentation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "# missing\n",
    "!pip install -e steel_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> A collection of Metrics used in the segmentation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcomatteo/steel_segmentation/blob/master/nbs/05_metrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from steel_segmentation.metadata import *\n",
    "from steel_segmentation.masks import *\n",
    "from steel_segmentation.datasets import *\n",
    "from steel_segmentation.dataloaders import *\n",
    "\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastcore.foundation import *\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section there are all the metric used to evaluate the performances of the deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 3, 256, 256]), torch.Size([20, 4, 256, 256]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "device = torch.device(\"cpu\")\n",
    "dls = get_segmnt_dls(bs=20)\n",
    "x, targs = dls.train.one_batch()\n",
    "x.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "x = x.cpu()\n",
    "x.device, targs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "model = smp.Unet(\"resnet18\", \n",
    "                 encoder_weights=\"imagenet\", \n",
    "                 classes=4, \n",
    "                 activation=None).to(device)\n",
    "logits = model(x)\n",
    "preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics for fastai API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some code from the fastai docs to test properly the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For testing: a fake learner and a metric that isn't an average\n",
    "@delegates()\n",
    "class TstLearner(Learner):\n",
    "    def __init__(self,dls=None,model=None,**kwargs): self.pred,self.xb,self.yb = None,None,None\n",
    "        \n",
    "#Go through a fake cycle with various batch sizes and computes the value of met\n",
    "def compute_val(met, x1, x2):\n",
    "    met.reset()\n",
    "    vals = [0,6,15,20]\n",
    "    learn = TstLearner()\n",
    "    for i in range(3):\n",
    "        learn.pred = x1[vals[i]:vals[i+1]]\n",
    "        learn.yb = ( x2[vals[i]:vals[i+1]], )\n",
    "        met.accumulate(learn)\n",
    "    return met.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModDiceMulti(Metric):\n",
    "    \"Averaged Dice metric (Macro F1) for multiclass target in segmentation\"\n",
    "\n",
    "    def __init__(self, axis=1): self.axis = axis\n",
    "    def reset(self): self.inter, self.union = {}, {}\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred.argmax(dim=self.axis)\n",
    "        y = learn.yb[0]\n",
    "        \n",
    "        if pred.shape != y.shape:\n",
    "            y = y.argmax(dim=self.axis)\n",
    "            \n",
    "        pred, targ = flatten_check(pred, y)\n",
    "        for c in range(learn.pred.shape[self.axis]):\n",
    "            p = torch.where(pred == c, 1, 0)\n",
    "            t = torch.where(targ == c, 1, 0)\n",
    "            p, t = TensorBase(p), TensorBase(t)\n",
    "            c_inter = (p*t).float().sum().item()\n",
    "            c_union = (p+t).float().sum().item()\n",
    "            if c in self.inter:\n",
    "                self.inter[c] += c_inter\n",
    "                self.union[c] += c_union\n",
    "            else:\n",
    "                self.inter[c] = c_inter\n",
    "                self.union[c] = c_union\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        binary_dice_scores = np.array([])\n",
    "        for c in self.inter:\n",
    "            binary_dice_scores = np.append(\n",
    "                binary_dice_scores, 2.*self.inter[c]/self.union[c] if self.union[c] > 0 else np.nan)\n",
    "        return np.nanmean(binary_dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_obj = ModDiceMulti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23427008996722556"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "compute_val(dice_obj, targs, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test purpose, we create a tensor, `x1`, as a prediction for the first channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1a = torch.ones(20,1,1,1)\n",
    "x1b = torch.clone(x1a)*0.5\n",
    "x1c = torch.clone(x1a)*0.3\n",
    "x1d = torch.clone(x1a)*0.1\n",
    "\n",
    "x1 = torch.cat((x1a,x1b,x1c,x1d),dim=1)   # Prediction: 20x4\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target is a flatten mask, used by fastai segmentation models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.]],\n",
       " \n",
       "         [[0.]],\n",
       " \n",
       "         [[0.]],\n",
       " \n",
       "         [[0.]],\n",
       " \n",
       "         [[0.]]]),\n",
       " torch.Size([20, 1, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.zeros(20,1,1)  # Target: 20xClass0\n",
    "x2[0:5], x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of `DiceMulti` into a simulated training with `compute_val` and a test Learner with `TstLearner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice metric = 1\n",
    "test_eq(compute_val(dice_obj, x1, x2), 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.ones(20,1,1)  # Target: 20xClass1\n",
    "# Dice metric = 0\n",
    "test_eq(compute_val(dice_obj, x1, x2), 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different scenario with a multiclass batch:\n",
    "- Class0 x 10\n",
    "- Class1 x 4\n",
    "- Class2 x 3\n",
    "- Class4 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2a = torch.zeros(10,1,1)\n",
    "x2b = torch.ones(4,1,1)\n",
    "x2c = torch.ones(3,1,1) * 2\n",
    "x2d = torch.ones(3,1,1) * 3\n",
    "\n",
    "x2 = torch.cat((x2a,x2b,x2c,x2d),dim=0)   # Target: 10xClass0, 4xClass1, 3xClass2, 3xClass4\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6666666666666666, 0, 0, 0]]\n",
      "0.16666666666666666\n"
     ]
    }
   ],
   "source": [
    "dice1 = (2*10)/(2*10+4+3+3)              # Dice: 2*TP/(2*TP+FP+FN)\n",
    "dice2 = 0\n",
    "dice3 = 0\n",
    "dice4 = 0\n",
    "# Value to be tested\n",
    "computed_dice = compute_val(dice_obj, x1, x2)\n",
    "# Dice metric = 0.1666\n",
    "test_eq(computed_dice, (dice1+dice2+dice3+dice4)/4)\n",
    "print(f\"[{[dice1, dice2, dice3, dice4]}]\")\n",
    "print(computed_dice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 10.0, 1: 0.0, 2: 0.0, 3: 0.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_obj.inter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 30.0, 1: 4.0, 2: 3.0, 3: 3.0}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_obj.union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dice_scores = np.array([])\n",
    "for c in dice_obj.inter:\n",
    "    binary_dice_scores = np.append(\n",
    "        binary_dice_scores, \n",
    "        2.*dice_obj.inter[c]/dice_obj.union[c] \n",
    "        if dice_obj.union[c] > 0 else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_dice_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.16666666666666666"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmean(binary_dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class KaggleDice(Metric):\n",
    "    def __init__(self, axis=1, eps=1e-9): self.axis, self.eps = axis, eps\n",
    "    def reset(self): self.inter, self.union = {}, {}\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        y = learn.yb[0]\n",
    "        preds = learn.pred\n",
    "        \n",
    "        if preds.shape == y.shape:\n",
    "            y = y.argmax(dim=self.axis)\n",
    "            \n",
    "        n, c = y.shape[0], preds.shape[self.axis]\n",
    "        \n",
    "        preds = preds.argmax(dim=self.axis).view(n, -1)\n",
    "        targs = y.view(n, -1)\n",
    "        \n",
    "#         pred, targ = flatten_check(preds, targs)\n",
    "        for i in range(0, c):\n",
    "            p = torch.where(preds == i, 1, 0)\n",
    "            t = torch.where(targs == i, 1, 0)\n",
    "            \n",
    "            p, t = TensorBase(p), TensorBase(t)\n",
    "            \n",
    "            c_inter = (p*t).sum(-1).float()#.item()\n",
    "            c_union = (p+t).sum(-1).float()#.item()\n",
    "            if i in self.inter:\n",
    "                self.inter[i] = torch.cat([self.inter[i], c_inter], dim=0)\n",
    "                self.union[i] = torch.cat([self.union[i], c_union], dim=0)\n",
    "            else:\n",
    "                self.inter[i] = c_inter\n",
    "                self.union[i] = c_union\n",
    "                \n",
    "#             print(f\"Iter n.{i}\\nintersect: {self.inter[i]}\\nunion: {self.union[i]}\", end=\"\\n\\n\")\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        binary_dice_scores = np.array([])\n",
    "        for c in range(len(self.inter)):\n",
    "            cond = self.union[c] == 0\n",
    "            val = 2.*(self.inter[c]+self.eps)/(self.union[c]+self.eps)\n",
    "            val[cond] = 1\n",
    "            binary_dice_scores = np.append(binary_dice_scores, val)\n",
    "        return np.nanmean(binary_dice_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The competition \"Evaluation\" metric is defined as:\n",
    "\n",
    "> This competition is evaluated on the mean Dice coefficient. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:\n",
    "\n",
    "$$\n",
    "J(A,B) = \\frac{2 * |A \\cap B|}{|A| \\cup |B|}\n",
    "$$\n",
    "\n",
    "> where X is the predicted set of pixels and Y is the ground truth. The Dice coefficient is defined to be 1 when both X and Y are empty. The leaderboard score is the mean of the Dice coefficients for each <ImageId, ClassId> pair in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_kaggle_obj = KaggleDice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7500000005"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_kaggle_dice = compute_val(dice_kaggle_obj, x1, x2); computed_kaggle_dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for `KaggleDice`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7500000005\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = [0,6,15,20]\n",
    "intersect, union = {}, {}\n",
    "\n",
    "for j in range(3):\n",
    "    pred = x1[vals[j]:vals[j+1]].clone()\n",
    "    targ = ( x2[vals[j]:vals[j+1]].clone(), )\n",
    "    targ = targ[0]\n",
    "    eps = 1e-9\n",
    "    # pred.shape, targ.shape\n",
    "\n",
    "    if pred.shape == targ.shape:\n",
    "        targ = targ.argmax(dim=1)\n",
    "    n, c = targ.shape[0], pred.shape[1]\n",
    "    # n, c\n",
    "\n",
    "    pred = pred.argmax(dim=1).view(n, -1)\n",
    "    targ = targ.view(n, -1)\n",
    "    # pred.shape, targ.shape\n",
    "    # pred.max(), targ.max()\n",
    "    for i in range(0, c):\n",
    "        p = torch.where(pred == i, 1, 0)\n",
    "        t = torch.where(targ == i, 1, 0)\n",
    "        p, t = TensorBase(p), TensorBase(t)\n",
    "        c_inter = (p*t).sum(-1).float()#.item()\n",
    "        c_union = (p+t).sum(-1).float()#.item()\n",
    "        if i in intersect:\n",
    "            intersect[i] = torch.cat([intersect[i], c_inter], dim=0)\n",
    "            union[i] = torch.cat([union[i], c_union], dim=0)\n",
    "        else:\n",
    "            intersect[i] = c_inter\n",
    "            union[i] = c_union\n",
    "    #     print(f\"Iter n.{i}\\nintersect: {intersect[i]}\\nunion: {union[i]}\", end=\"\\n\\n\")\n",
    "\n",
    "binary_dice_scores = np.array([])\n",
    "for c in intersect.keys():\n",
    "    cond = union[c] == 0\n",
    "    val = 2.*(intersect[c]+eps)/(union[c]+eps)\n",
    "    val[cond] = 1\n",
    "    binary_dice_scores = np.append(binary_dice_scores, val)\n",
    "\n",
    "num = 4\n",
    "fig, axs = plt.subplots(num, 1, sharex=True)\n",
    "for i in range(num):\n",
    "    axs[i].plot(binary_dice_scores[(i*20):((i*20)+20)])\n",
    "    axs[i].set_title(i, loc='right', y=.6, pad=-7.)\n",
    "print(binary_dice_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_close(computed_kaggle_dice, binary_dice_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test `KaggleDice` with a real shape batch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chs = 4\n",
    "\n",
    "x3a = ((torch.sigmoid(torch.rand(chs,1,1)) > 0.65).float()).unsqueeze(0).expand(5, 4, 1, 1)\n",
    "x3b = ((torch.sigmoid(torch.rand(chs,1,1)) > 0.65).float()).unsqueeze(0).expand(5, 4, 1, 1)\n",
    "x3c = ((torch.sigmoid(torch.rand(chs,1,1)) > 0.65).float()).unsqueeze(0).expand(5, 4, 1, 1)\n",
    "x3d = ((torch.sigmoid(torch.rand(chs,1,1)) > 0.65).float()).unsqueeze(0).expand(5, 4, 1, 1)\n",
    "\n",
    "x3 = torch.cat((x3a,x3b,x3c,x3d),dim=0); x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x3.squeeze(-1).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x3.argmax(axis=1).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x4a = torch.tensor([1., 0., 0., 0.]).unsqueeze(0).unsqueeze(-1).expand(5, 4, 1)\n",
    "x4b = torch.tensor([0., 1., 0., 0.]).unsqueeze(0).unsqueeze(-1).expand(5, 4, 1)\n",
    "x4c = torch.tensor([0., 0., 1., 0.]).unsqueeze(0).unsqueeze(-1).expand(5, 4, 1)\n",
    "x4d = torch.tensor([0., 0., 0., 1.]).unsqueeze(0).unsqueeze(-1).expand(3, 4, 1)\n",
    "x4e = torch.tensor([0., 0., 0., 0.]).unsqueeze(0).unsqueeze(-1).expand(2, 4, 1)\n",
    "\n",
    "x4 = torch.cat((x4a,x4b,x4c,x4d, x4e),dim=0)   # Target: 5xClass0, 5xClass1, 5xClass2, 5xClass4\n",
    "x4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x4.squeeze(-1).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x4.argmax(axis=1).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.55964285892866"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "computed_kaggle_dice = compute_val(dice_kaggle_obj, x3, x4); computed_kaggle_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55964285892866\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAiyElEQVR4nO3daXRU553n8e9fKyCEWCSQUAHCGGyDDUZSYzteYrcTG+MFgzg5trN2nMO4Y8+ZPjM50+5OOu3p+EW6+8xMTtpbaNsn7aQTJ4PAS1vYzmonsR2jksVqgzGGUJJAYhUgQNszL6pIV4oqqVSLblXp9zlHh6p7n0f3p0vxp3TvU89jzjlERCR35XkdQERE0kuFXkQkx6nQi4jkOBV6EZEcp0IvIpLjCrwOEE15ebmrqanxOoaISNbw+/2HnXMV0fZlZKGvqamhubl5xP027zvK4KCGi0riFswoZUpJkdcxREbMzPbH2peRhT5RX3jmXc70DXgdQ7LYVXOn8pP/co3XMURSKqcK/bNf+jP0ATBJ1Os7D/H9t/ax7/BpaspLvI4jkjI5VeivmTfN6wiSxS6qmMhzb+9jQ0uA/37LJV7HEUkZjboRCaksG8e1F5fT2NKmez2SU1ToRcKsqfPRdvwM73x8xOsoIimjQi8S5tZFlZQWF9Dob/M6ikjKqNCLhBlXmM/ti6vYtL2D0+f6vY4jkhIq9CIR1tT56OkdYNP2g15HEUkJFXqRCHVzplAzbQKN/oDXUURSQoVeJIKZ0VDr4+29RzhwtMfrOCJJU6EXiWJVbTUAG9/TTVnJfir0IlH4pkzgE/Om0dgS0KetJeup0IvE0FDrY/+RHpr3H/M6ikhSVOhFYlh+eSUTivJZ36ybspLdVOhFYigpLmDFFVW8sq2DM72aFVWyV1KF3syWm9kuM9tjZg9H2X+jmZ0ws9bQ1zeTOZ7IaGuo9XHqXD+v79SYesleCRd6M8sHHgduAxYC95rZwihNf+OcuzL09Q+JHk/EC1fNnYpvynjWa0y9ZIijR4+yatUqSkpKmDNnDj/60Y+G7ZPMNMXLgD3Oub0AZvY8sBLYmcT3FMkoeXnG6lof//LLD+k4cYaqsvFeR5Ix7sEHH6SoqIhDhw7R2trK7bffzpIlS4bsk8ylm2rgQNjzQGhbpGvMbIuZbTKzRbG+mZmtNbNmM2vu6upKIpZIajXUVuMcbGjRmHrx1unTp2lsbORb3/oWEydO5LrrruOuu+7iBz/4wZD9kin0FmVb5IDjFmCOc24J8C/AC7G+mXNunXOu3jlXX1ERdX1bEU/MmVbCspqpGlMvntu9ezf5+fksWLDgj9uWLFnCjh07huyXTKEPALPCnvuA9vAGzrlu59yp0OMmoNDMypM4pognGuqq2dt1mtYDx72OImPYqVOnKCsr+5NtZWVlnDx5csh+yRT6zcB8M5trZkXAPcBL4Q3MrNLMLPR4Weh4WtFBss6KK6oYV5inm7LiqYkTJ9Ld3f0n27q7uyktLR2yX8KF3jnXDzwEvAa8D/zUObfDzB4wswdCzdYA281sC/Bd4B6n330lC5WOK2T5okpe3tLO2T6NqRdvLFiwgP7+fj788MM/btuyZQuLFsW8/QmAZWLdra+vd83NzV7HEPkTv/3wMJ975vc8dt9S7lg80+s4Mkbdc889mBlPP/00ra2trFixgrfeeovLL7/c75yrj9ZHn4wVidM186ZRVTZO89SLp5544gnOnDnD9OnTuffee3nyySeHfUefzDh6kTElP89YtbSap974iM7us0yfNM7rSDIGTZ06lRdeeGFEffSOXmQEGup8DDp4oVVj6iV7qNCLjMC8ioksnT2ZRn+bxtRL1lChFxmhNXU+dh06yfa27uEbi2QAFXqREbpj8UyKCvJobNFNWckOKvQiI1Q2vpBbFs7gxdY2evsHvY4jMiwVepEENNT5ONbTxy8/6PQ6isiwVOhFEnD9xeVUlBZrSgTJCir0IgkoyM9j9dJqfr2rkyOnznkdR2RIKvQiCWqo89E/6HixtX34xiIeUqEXSdCCGaUs9pXp8o1kPBV6kSQ01PrY2dHNznaNqZfMpUIvkoS7lsykMN80pl4ymgq9SBKmlBRx86XBMfV9AxpTL5lJhV4kSQ11Pg6f6uWNXVrUXjJTUoXezJab2S4z22NmD0fZb2b23dD+rWZWm8zxRDLRjZdUMK2kSJdvJGMlXOjNLB94HLgNWAjca2YLI5rdBswPfa0Fnkz0eCKZqjA/j5VXVvOL9zs5drrX6zgiF0hm4ZFlwB7n3F4AM3seWAnsDGuzEngutE7sO2Y22cyqnHMdSRxXJOOsqfPx7O8+5qk3PuK6+eVex5EsVZifx9UXTUv5902m0FcDB8KeB4Cr4mhTDVxQ6M1sLcF3/cyePTuJWCKjb+HMSVxRXcb33tzL997c63UcyVLlE4tp/sanUv59kyn0FmVb5EoM8bQJbnRuHbAOgouDJ5FLxBP/9uVl7O065XUMyWIF+ekZH5NMoQ8As8Ke+4DIz4LH00YkJ0wtKWJqyVSvY4hcwBJdDs3MCoDdwM1AG7AZuM85tyOsze3AQ8AKgpd1vuucWxbH9+4C9icUDMqBwwn2HQ3KlxzlS47yJSeT881xzlVE25HwO3rnXL+ZPQS8BuQDzzrndpjZA6H9TwFNBIv8HqAH+Is4v3fUsPEws2bnXH2i/dNN+ZKjfMlRvuRker5Ykrl0g3OuiWAxD9/2VNhjBzyYzDFERCQ5+mSsiEiOy8VCv87rAMNQvuQoX3KULzmZni+qhG/GiohIdsjFd/QiIhJGhV5EJMep0IuI5LikhlemS3l5uaupqfE6hohI1vD7/YdT/oGpdKqpqaG5udnrGCIyiloPHOdnOw96mmGxbzK3Lqr0NEOizCzmbAIZWehFZGxxzvHX67eyu/Mk+RZtLsT0G3CO4oI83v36p5g0rtCTDOmiQi8intvR3s2uQyd59O7L+dzVczzJ0HrgOHc//juatnZwz7LcmipdN2NFxHPr/QGKCvK4c/FMzzIs8ZUxr6IkJ5eEVKEXEU/19g/yYmsbn144g7IJ3l0yMTPW1M1i875j7Dt82rMc6aBCLyKe+tWuTo719LGm1ud1FFYtrSbPYEOOvatXoRcRT633B6goLeb6DFhrt7JsHNdeXE5jSxuDg7kzPYwKvYh45sipc/zqg05WLa1O2zJ6I7Wmzkfb8TO88/ERr6OkTGacWREZk15sbad/0NGQAZdtzrt1USWlxQWs9+fO5RsVehHxTGNLgCuqy7ikstTrKH80rjCfO5ZU8er2g5w+1+91nJRQoRcRT7zf0c2O9m4aaqu9jnKBhlofPb0DNG3r8DpKSqjQi4gnGv0BCvONu67MvEJfN2cKNdMm5MyYehV6ERl1fQODvNDazp9fOp2pJUVex7mAmdFQ6+OdvUc5cLTH6zhJU6EXkVH35u4uDp86l1E3YSOtCl1S2tDS5nGS5MVV6M1suZntMrM9ZvZwlP2fNbOtoa+3zGxJ2L59ZrbNzFrNTFNSigiNLQGmlRRx06XTvY4Sk2/KBD4xbxqNLQGyfcnVYQu9meUDjwO3AQuBe81sYUSzj4FPOucWA9/iwgV0b3LOXemcq09BZhHJYsd7evn5zk7uunImhRkydj6Whloffzjaw+Z9x7yOkpR4zvIyYI9zbq9zrhd4HlgZ3sA595Zz7vyZeAfI3N/HRMRTL29pp3dgkDV1mV8mbruikpKifBqzfEx9PIW+GjgQ9jwQ2hbL/cCmsOcOeN3M/Ga2NlYnM1trZs1m1tzV1RVHLBHJRuv9AS6tLGXRzDKvowxrQlEBt11RxSvbOjjTO+B1HAAee+wx6uvrKS4u5ktf+lJcfeIp9NFWAYh6wcrMbiJY6P86bPO1zrlagpd+HjSzG6L1dc6tc87VO+fqKyqiroYlIlnuw0Mn2RI4kRXv5s9bU+fj1Ll+Xtvh7epX582cOZNvfOMbfPnLX467TzyFPgDMCnvuA9ojG5nZYuBpYKVz7o+TRDjn2kN/dgIbCV4KEpExaH1LgPw8Y2UGjp2PZVnNVHxTxmfMlAirV6/m7rvvZtq0aXH3iafQbwbmm9lcMysC7gFeCm9gZrOBDcDnnXO7w7aXmFnp+cfALcD2uNOJSM4YGHS88F4bNy6ooKK02Os4ccvLM1bX+vjdR4dpP37G6zgJGbbQO+f6gYeA14D3gZ8653aY2QNm9kCo2TeBacATEcMoZwC/NbMtwLvAK865V1P+U4hIxvvtnsMc6j6XVZdtzmuorcY52Phedo6pj2vNWOdcE9AUse2psMdfAb4Spd9eYEnkdhEZe9b7A5SNL+TPL8vcsfOxzJlWwrKaqTT6A3z1xnmYRwuYJyqzB7GKSE44caaP13ccZOWVMykuyPc6TkLW1PnYe/g07x047nWUEVOhF5G0e2VrB+f6BzN6yoPh3HZFJeMK8zy/Kdvf38/Zs2cZGBhgYGCAs2fP0t8/9HTKKvQiknaNLQHmT5/IYl/mj52PpXRcIbddXsXLW9o52+fdmPpHH32U8ePH8+1vf5sf/vCHjB8/nkcffXTIPir0IpJWe7tO4d9/jIY6X9Zd247UUOvj5Nl+frbzkGcZHnnkEZxzf/L1yCOPDNlHhV5E0mpDSxt5BquWZs/Y+ViumTeNqrJxWTdPvQq9iKTN4KBjQ0uA6+dXMGPSOK/jJC0/z1hdW82bu7s41H3W6zhxU6EXkbR5e+8R2k+cpSELx87HsrrWx6CDF7JoTL0KvYikTaM/QOm4Am5ZOMPrKCkzr2IitbMnZ9U89Sr0IpIWp871s2n7Qe5YPJNxhdk5dj6Whjofuw+dYlvbCa+jxEWFXkTSomlbB2f6BlhTl/03YSPdsXgmRQV5WTNPvQq9iKTFen+AueUl1M6e4nWUlCsbX8gtC2fw4pZ2zvVnxjz1Q1GhF5GU+8ORHt79+CgNtdVZP3Y+loY6H8d7+vjVB51eRxmWCr2IpFxjSwAzWJXFUx4M5/qLy5leWuz5lAjxUKEXkZQaHHRseC/AJ+ZNo3ryeK/jpE1Bfh6rllbzq11ddJ0853WcIanQi0hKvbvvKAeOnsnKeedHqqHOx8Cg48XWzB5Tr0IvIinV6A9QUpTPrYsqvY6SdgtmlLLYV0Zjiwq9iIwRPb39NG3rYMUVVUwoimtdo6zXUOvj/Y5udrRn7ph6FXoRSZlXtx/kdO/AmLhsc95dS2ZSmG80+jP3XX1chd7MlpvZLjPbY2YPR9lvZvbd0P6tZlYbb18RyR2NLQFmTR3Pn9VM9TrKqJlSUsTNl87gxdY2+gYGvY4T1bCF3szygceB24CFwL1mtjCi2W3A/NDXWuDJEfQVkRzQdvwMb310hIZaH3l5uTl2PpY1dT6OnO7l17u6vI4SVTwX0ZYBe0ILfWNmzwMrgZ1hbVYCz7ngDD/vmNlkM6sCauLomzL/9OoHGfs/qkiu23XoFM6R1csFJuqTl1QwraSI//uz3bz78ZGEv09JcQF/9akFKUwWFE+hrwYOhD0PAFfF0aY6zr4AmNlagr8NMHv27DhiXegnmw9wxsMlvkTGujsWVzFr6gSvY4y6wvw8vnzdXB7/1R72HTmd8PeZNrHIs0If7XewyLk5Y7WJp29wo3PrgHUA9fX1Cc396f+7TyfSTUQkaQ/edDEP3nSx1zGiiqfQB4BZYc99QHucbYri6HsBv99/2Mz2x5EtmnLgcIJ9R4PyJUf5kqN8ycnkfHNi7Yin0G8G5pvZXKANuAe4L6LNS8BDoWvwVwEnnHMdZtYVR98LOOcq4sgVlZk1O+fqE+2fbsqXHOVLjvIlJ9PzxTJsoXfO9ZvZQ8BrQD7wrHNuh5k9ENr/FNAErAD2AD3AXwzVNy0/iYiIRBXXR9ecc00Ei3n4tqfCHjvgwXj7iojI6MnFT8au8zrAMJQvOcqXHOVLTqbni8qyZXFbERFJTC6+oxcRkTAq9CIiOU6FXkQkx8UzqdmzZtZpZttj7B9q5sp9ZrbNzFrNrDmVwUVEJD7xDK/8PvAY8FyM/eEzV15FcObK8PlsbnLOjeiTZOXl5a6mpmYkXURExjS/33841odN4/nA1JtmVjNEk6gzVzrnOhKLCzU1NTQ36xcAEZF4DTVtTCqu0ceauRKCE5i9bmb+0OyUMZnZWjNrNrPmrq7MnNNZRCQbpaLQDzVD5bXOuVqCl3ceNLMbYn0T59w651y9c66+oiLhqW5ERCRCKgp9zNktnXPn/+wENhJcxEREREZRKgr9S8AXQqNvruY/Z64sMbNSADMrAW4Boo7cERGR9Bn2ZqyZ/Ri4ESg3swDw90AhDD1zJTAD2Ghm54/zI+fcqynOLyIiw4hn1M29w+yPOnNlaJ3YJYlHExGRVNAnY0VEcpwKvYhIjlOhFxHJcSr0IiI5ToVeRCTHqdCLiOQ4FXoRkRynQi8ikuNU6EVEcpwKvYhIjlOhFxHJIufOneP+++9nzpw5lJaWsnTpUjZt2jRkn3iWEhQRkQzR39/PrFmzeOONN5g9ezZNTU185jOfASiK1Sfdi4MvN7NdoX0PJ/JDiYjIfyopKeGRRx6hpqaGvLw87rjjDubOnQswIVafeC7dfB9YPsT+8MXB1xJcHBwzywceD+1fCNxrZgvj+UFERCQ+hw4dYvfu3QBnY7VJ2+LgQA2wJzRdMWb2fKjtzrh/ghH6Xy/vYGd7d7q+vYhIWi2cOYm/v3NR3O37+vr47Gc/yxe/+EXWrVsXs9Cnc3HwoRYNv4AWBxcRid/g4CCf//znKSoq4rHHHhuybSpuxsZaHHyoRcMv3OHcOmAdQH19fcx2QxnJ/4QiItnKOcf999/PoUOHaGpqorCwcMj2qSj0sRYHL4qxXUREkvCXf/mXvP/++/z85z9n/Pjxw7ZPRaF/CXgodA3+Kv5zcfAuYL6ZzQXagHuA+1JwPBGRMWv//v1873vfo7i4mMrKyvBdU2P1Sdvi4M65fjN7CHgNyAeedc7tSODnEhGRkDlz5hAc+/KnzOxorD5pWxw8tK+J4H8EIiLiEU2BICKS41ToRURynAq9iEiOU6EXEclxKvQiIjlOhV5EJMep0IuI5DgVehGRHKdCLyKS41ToRURynAq9iEiOU6EXEclxKvQiIjkurkJvZsvNbJeZ7TGzh6Psn2JmG81sq5m9a2aXh+3bZ2bbzKzVzJpTGV5ERIYXz3z0+cDjwKcJria12cxecs6FL/L9t0Crc26VmV0aan9z2P6bnHOHU5hbRETiFM87+mXAHufcXudcL/A8sDKizULgFwDOuQ+AGjObkdKkIiKSkHgKfTVwIOx5ILQt3BZgNYCZLQPmEFwjFoILgr9uZn4zWxvrIGa21syazay5q6sr3vwiIjKMeAq9RdkWuY7Vt4EpZtYK/FfgPaA/tO9a51wtcBvwoJndEO0gzrl1zrl651x9RUVFXOFFRGR48SwOHgBmhT33Ae3hDZxz3YTWijUzAz4OfeGcaw/92WlmGwleCnpzqAP6/f7DZrY/zp8hUjmQyfcDlC85ypcc5UtOJuebE2tHPIV+MzDfzOYCbcA9wH3hDcxsMtATuob/FeBN51y3mZUAec65k6HHtwD/MNwBnXMJv6U3s2bnXH2i/dNN+ZKjfMlRvuRker5Y4lkcvN/MHgJeA/KBZ51zO8zsgdD+p4DLgOfMbADYCdwf6j4D2Bh8k08B8CPn3Kup/zFERCSWeN7R45xrApoitj0V9vhtYH6UfnuBJUlmFBGRJOTiJ2PXeR1gGMqXHOVLjvIlJ9PzRWXORQ6gERGRXJKL7+hFRCSMCr2ISI5ToRcRyXFpL/Rm9qyZdZrZ9nQfS0RELpT2m7GhKQ9OAc855y4frj1AeXm5q6mpGfGxBgZ1Y1mSk58XbcYPGS36N5z4a9Dv9x+O9WHTuMbRJ8M596aZ1YykT01NDc3NI5+6/rK/e5UzfQMj7idy3u2Lq3j8vlqvY4xJ/3P9Fn7aHPA6hqfKJxbT/I1PJdR3qGlj0l7o4xWa2XItwOzZsxP6Hn+74lL69Y5AEvTWR0d4dftBuk6eo6K02Os4Y8qJM3280NrOJxdUcOMlY3dSw/GF+Wn5vhlT6J1z6wh9GKG+vj6hav35a2pSGUnGmOvnl/OznYd4sbWNr1x/kddxxpRXtnbQ2z/I/7hlAYt9k72Ok3M06kYk5OLppSyZNZn1/rF9+cAL6/0HWDBjIldUl3kdJSep0IuEWVNbzQcHT7Kj/YTXUcaMvV2naPnDcRpqfYQmQJQUG43hlT8G3gYuMbOAmd0/XB8Rr9y5ZCZF+Xl6Vz+KGlsC5BmsWhq5cJ2kStoLvXPuXudclXOu0Dnnc849k+5jiiRq8oQiPrVwOi+2ttPbP+h1nJw3MOjY0NLGDQsqmD5pnNdxcpYu3YhEaKj1cfR0L7/e1el1lJz39kdH6DhxloZa3/CNJWEq9CIRblhQQfnEYhpbdPkm3RpbApSOK+DTC2d4HSWnqdCLRCjMz+PuK2fyyw86OXq61+s4Oevk2T42be/gziUzGZem8eMSpEIvEkVDnY++AcdLrW1eR8lZm7Yd5GzfIGvqdNkm3VToRaK4rGoSi2ZOorFFhT5d1vsDXFRewtJZk72OkvNU6EViWFPnY1vbCXYdPOl1lJzzhyM9vLvvKA11Gjs/GlToRWK4a8lMCvJMN2XToLElgBmsrtXY+dGgQi8Sw7SJxdx06XQ2tLTRP6Ax9akyOOhobAlw7bxyqsrGex1nTFChFxnCmjofh0+d4zcfHvY6Ss54d99RAsfO6CbsKFKhFxnCTZdMZ8qEQtbr8k3KrPcHmFhcwK2LKr2OkrU+97nPUVVVxaRJk1iwYAFPP/30kO0zZppikUxUVJDHyiur+dHv/8CJnj7KJhR6HSmrnT7XT9O2Du5cPJPxRRo7n6i/+Zu/4ZlnnqG4uJgPPviAG2+8EWBCrPZ6Ry8yjDV1PnoHBnl5a7vXUbLeq9sP0tM7QIMu2yRl0aJFFBcHF8cxs/Mjl2KulqNCLzKMRTMncWllqWa0TIHGlgCzp07gz2qmeB0l6331q19lwoQJXHrppVRVVQHEnFtbhV5kGGZGQ62P1gPH2dN5yus4WStwrIe3PjqieedT5IknnuDkyZP85je/YfXq1QAxV+ZToReJw8qlM8nXmPqkbAx9ylhj51MnPz+f6667jkAgABBzsV0VepE4TC8dxycXVLCxpY0BLUA/Ys4Fx85ffdFUZk2Nec9QEtTf3w+6Ri+SvIZaHwe7z/LWRxpTP1L+/cfYd6RH886nQGdnJ88//zynTp1iYGCA1157jR//+McAMefqUKEXidPNl02nbHyhbsomoLElwISifFZcUeV1lKxnZjz55JP4fD6mTJnC1772Nb7zne8AHI/VR+PoReI0rjCfO5dUsd4foPtsH5PGaUx9PM72DfAfWzpYfnklJcUqOcmqqKjgjTfeuGD72rVrY/bRO3qREVhTN4uzfYM0be3wOkrWeG3HQU6e69eUBx5SoRcZgSW+MuZVlGj0zQis9weonjyeq+dO8zrKmKVCLzICZkZDnY/N+46x7/Bpr+NkvIMnzvK7PYdZXVtNXp7GzntFhV5khFYv9ZFnsEHv6oe14b0Agw6NtvGYCr3ICFWWjePai8tpbGljUGPqY3LO0egPUD9nCjXlJV7HGdNU6EUSsKbOR9vxM7zz8RGvo2SsLYETfNR1WjdhM4AKvUgCbl1USWlxAY1+LR4ey3r/AYoL8lixWGPnvaZCL5KAcYX53L64ik3bOzh9rt/rOBnnbN8AL2/p4NZFlfq8QQZQoRdJ0Jo6Hz29A2zaftDrKBnnF+93cuJMny7bZAgVepEE1c2ZQs20CTRqSoQLNLYEqJwUvGkt3lOhF0nQ+Xnq3957hANHe7yOkzE6T57ljd1drKqtJl9j5zOCCr1IElaF5lbf+J5uyp734nvtDAw6jZ3PICr0IknwTZnAJ+ZNo7ElgHMaU++cY70/wJWzJnPx9Ilex5EQFXqRJDXU+th/pIfm/ce8juK5He3d7Dp0Uot/Z5hRKfRmttzMdpnZHjN7eDSOKTJall9eyYSifNY366bsen+Aovw87tTY+YyS9kJvZvnA48BtwELgXjNbmO7jioyWkuICVlxRxSvbOjjTO+B1HM/09g/yYmsbn144g8kTiryOI2FGYxWAZcAe59xeADN7HlgJ7ByFY4uMioZaH+v9ATa8F+DTl83wOo4nfrvnMMd6+mio0+LfmWY0Cn01cCDseQC4ahSOKzJqrpo7Fd+U8Xx943a+vnG713E8Uz6xmBvmV3gdQyKMRqGPNpD2guEJZrYWWAswe/bsdGcSSam8PONfv1BPyx/G9g3ZJb7JFORrjEemGY1CHwBmhT33Ae2RjZxz64B1APX19RqnJlnnsqpJXFY1yesYIhewdI/9NbMCYDdwM9AGbAbuc87tGKJPF7A/wUOWA4cT7DsalC85ypcc5UtOJueb45yLet0s7e/onXP9ZvYQ8BqQDzw7VJEP9Un4Ip+ZNTvn6hPtn27KlxzlS47yJSfT88UyGpducM41AU2jcSwREflTumsiIpLjcrHQr/M6wDCULznKlxzlS06m54sq7TdjRUTEW7n4jl5ERMKo0IuI5LisLPTDzYZpQd8N7d9qZrWjnG+Wmf3KzN43sx1m9t+itLnRzE6YWWvo65ujnHGfmW0LHbs5yn7PzqGZXRJ2XlrNrNvM/iqizaiePzN71sw6zWx72LapZvYzM/sw9OeUGH3TPntrjHz/bGYfhP7+NprZ5Bh9h3wtpDHfI2bWFvZ3uCJGX6/O30/Csu0zs9YYfdN+/pLmnMuqL4Jj8T8CLgKKgC3Awog2K4BNBKdfuBr4/ShnrAJqQ49LCX5gLDLjjcB/eHge9wHlQ+z39BxG/H0fJPhhEM/OH3ADUAtsD9v2T8DDoccPA/8YI/+Qr9c05rsFKAg9/sdo+eJ5LaQx3yPA1+L4+/fk/EXs/9/AN706f8l+ZeM7+j/Ohumc6wXOz4YZbiXwnAt6B5hsZqM2QbZzrsM51xJ6fBJ4n+DkbtnE03MY5mbgI+dcop+UTgnn3JvA0YjNK4F/Cz3+N+DuKF3jeb2mJZ9z7nXnXH/o6TsEpx/xRIzzFw/Pzt95ZmbAZ4Afp/q4oyUbC3202TAji2g8bUaFmdUAS4HfR9l9jZltMbNNZrZodJPhgNfNzB+aUC5SppzDe4j9D8zL8wcwwznXAcH/3IHpUdpkynn8MsHf0KIZ7rWQTg+FLi09G+PSVyacv+uBQ865D2Ps9/L8xSUbC308s2HGNWNmupnZRKAR+CvnXHfE7haClyOWAP8CvDDK8a51ztUSXBDmQTO7IWK/5+fQzIqAu4D/F2W31+cvXplwHr8O9AP/HqPJcK+FdHkSmAdcCXQQvDwSyfPzB9zL0O/mvTp/ccvGQh/PbJhxzZiZTmZWSLDI/7tzbkPkfudct3PuVOhxE1BoZuWjlc851x76sxPYSPBX5HCen0OC/3BanHOHInd4ff5CDp2/nBX6szNKG0/Po5l9EbgD+KwLXVCOFMdrIS2cc4eccwPOuUHgX2Mc1+vzVwCsBn4Sq41X528ksrHQbwbmm9nc0Du+e4CXItq8BHwhNHLkauDE+V+xR0Pomt4zwPvOuf8To01lqB1mtozg38WRUcpXYmal5x8TvGkXuVqGp+cwJOY7KS/PX5iXgC+GHn8ReDFKm3her2lhZsuBvwbucs71xGgTz2shXfnC7/msinFcz85fyKeAD5xzURcE9vL8jYjXd4MT+SI4ImQ3wbvxXw9tewB4IPTYCK5T+xGwDagf5XzXEfz1civQGvpaEZHxIWAHwVEE7wCfGMV8F4WOuyWUIRPP4QSChbssbJtn54/gfzgdQB/Bd5n3A9OAXwAfhv6cGmo7E2ga6vU6Svn2ELy+ff41+FRkvlivhVHK94PQa2srweJdlUnnL7T9++dfc2FtR/38JfulKRBERHJcNl66ERGREVChFxHJcSr0IiI5ToVeRCTHqdCLiOQ4FXoRkRynQi8ikuP+P/C8X6BtkMdbAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = [0,6,15,20]\n",
    "intersect, union = {}, {}\n",
    "\n",
    "for j in range(3):\n",
    "    pred = x3[vals[j]:vals[j+1]].clone()\n",
    "    targ = ( x4[vals[j]:vals[j+1]].clone(), )\n",
    "    targ = targ[0]\n",
    "    eps = 1e-9\n",
    "\n",
    "    if pred.shape == targ.shape:\n",
    "        targ = targ.argmax(dim=1)\n",
    "    n, c = targ.shape[0], pred.shape[1]\n",
    "\n",
    "    pred = pred.argmax(dim=1).view(n, -1)\n",
    "    targ = targ.view(n, -1)\n",
    "    for i in range(0, c):\n",
    "        p = torch.where(pred == i, 1, 0)\n",
    "        t = torch.where(targ == i, 1, 0)\n",
    "        p, t = TensorBase(p), TensorBase(t)\n",
    "        c_inter = (p*t).sum(-1).float()#.item()\n",
    "        c_union = (p+t).sum(-1).float()#.item()\n",
    "        if i in intersect:\n",
    "            intersect[i] = torch.cat([intersect[i], c_inter], dim=0)\n",
    "            union[i] = torch.cat([union[i], c_union], dim=0)\n",
    "        else:\n",
    "            intersect[i] = c_inter\n",
    "            union[i] = c_union\n",
    "\n",
    "binary_dice_scores = np.array([])\n",
    "for c in intersect.keys():\n",
    "    cond = union[c] == 0\n",
    "    val = 2.*(intersect[c]+eps)/(union[c]+eps)\n",
    "    val[cond] = 1\n",
    "    binary_dice_scores = np.append(binary_dice_scores, val)\n",
    "\n",
    "num = 4\n",
    "fig, axs = plt.subplots(num, 1, sharex=True)\n",
    "for i in range(num):\n",
    "    axs[i].plot(binary_dice_scores[(i*20):((i*20)+20)])\n",
    "    axs[i].set_title(i, loc='right', y=.6, pad=-7.)\n",
    "\n",
    "test_eq(computed_kaggle_dice, binary_dice_scores.mean())\n",
    "print(binary_dice_scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Real masks have a problem with the hardnegatives examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 4, 256, 256]), torch.Size([20, 4, 256, 256]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "# with real batch, recompute cell above to test\n",
    "x3, x4 = preds.cpu(), targs\n",
    "x3.shape, x4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def dice_kaggle(\n",
    "    preds: Tensor, \n",
    "    targs: Tensor, \n",
    "    iou: bool = False, \n",
    "    eps: float = 1e-8\n",
    "):\n",
    "    \"\"\"\n",
    "    The metric of the competition, \n",
    "    if there's no defect in `targs` and no defects in `preds`: dice=1.\n",
    "    \"\"\"\n",
    "    n, c = targs.shape[0], preds.shape[1]\n",
    "    preds = preds.argmax(dim=1).view(n, -1)\n",
    "    targs = targs.view(n, -1)\n",
    "\n",
    "    intersect_list, union_list = [], []\n",
    "    for i in range(c):\n",
    "        inp, trgs = TensorBase(preds), TensorBase(targs)\n",
    "        \n",
    "        inter = ((inp == i) & (trgs == i)).sum(-1).float()\n",
    "        un = ((inp == i).sum(-1) + (trgs == i).sum(-1))\n",
    "        \n",
    "        intersect_list.append(inter)\n",
    "        union_list.append(un)\n",
    "\n",
    "    intersect = torch.stack(intersect_list)\n",
    "    union = torch.stack(union_list)\n",
    "\n",
    "    if not iou:\n",
    "        dice = ((2.0 * intersect + eps) / (union + eps))\n",
    "        return dice.mean()\n",
    "    else:\n",
    "        int_over_union = ((intersect + eps) / (union - intersect + eps)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorBase(0.7500)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dice_kag = dice_kaggle(x1, x2)\n",
    "dice_kag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ne(computed_kaggle_dice, dice_kag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "fastai_dice_metrics = [ModDiceMulti()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersection Over Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def iou(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None,\n",
    "    activation: str = \"Sigmoid\"\n",
    "):\n",
    "    \"\"\"\n",
    "    https://github.com/catalyst-team/catalyst/blob/master/catalyst/dl/utils/criterion/iou.py\n",
    "    Args:\n",
    "        outputs (torch.Tensor): A list of predicted elements\n",
    "        targets (torch.Tensor):  A list of elements that are to be predicted\n",
    "        eps (float): epsilon to avoid zero division\n",
    "        threshold (float): threshold for outputs binarization\n",
    "        activation (str): An torch.nn activation applied to the outputs.\n",
    "            Must be one of [\"none\", \"Sigmoid\", \"Softmax2d\"]\n",
    "    Returns:\n",
    "        float: IoU (Jaccard) score\n",
    "    \"\"\"\n",
    "    outputs = F.sigmoid(outputs)\n",
    "\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold).float()\n",
    "\n",
    "    intersection = torch.sum(targets * outputs)\n",
    "    union = torch.sum(targets) + torch.sum(outputs)\n",
    "    iou = intersection / (union - intersection + eps)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorMask(0.0147)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "iou(logits, targs, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2286577459675328"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "jacc_metric = JaccardCoeff()\n",
    "compute_val(jacc_metric, preds, targs.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def iou_binary_metric(preds, labels, EMPTY=1., ignore=None, per_image=True):\n",
    "    \"\"\"\n",
    "    IoU for foreground class\n",
    "    binary: 1 foreground, 0 background\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        intersection = ((label == 1) & (pred == 1)).sum()\n",
    "        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n",
    "        if not union:\n",
    "            iou = EMPTY\n",
    "        else:\n",
    "            iou = float(intersection) / float(union)\n",
    "        ious.append(iou)\n",
    "    iou = mean(ious)    # mean accross images if per_image\n",
    "    return 100 * iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def iou_metric(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n",
    "    \"\"\"\n",
    "    Array of IoU for each (non ignored) class\n",
    "    \"\"\"\n",
    "    if not per_image:\n",
    "        preds, labels = (preds,), (labels,)\n",
    "    ious = []\n",
    "    for pred, label in zip(preds, labels):\n",
    "        iou = []    \n",
    "        for i in range(C):\n",
    "            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n",
    "                label, pred = TensorBase(label), TensorBase(pred)\n",
    "                intersection = ((label == i) & (pred == i)).sum()\n",
    "                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n",
    "                if not union:\n",
    "                    iou.append(EMPTY)\n",
    "                else:\n",
    "                    iou.append(float(intersection) / float(union))\n",
    "        ious.append(iou)\n",
    "    ious = [np.mean(iou) for iou in zip(*ious)] # mean accross images if per_image\n",
    "    return 100 * np.array(ious)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
    "    \"\"\"computes IoU for one ground truth mask and predicted mask\"\"\"\n",
    "    pred[label == ignore_index] = 0\n",
    "    ious = []\n",
    "    for c in classes:\n",
    "        label_c = label == c\n",
    "        if only_present and np.sum(label_c) == 0:\n",
    "            ious.append(np.nan)\n",
    "            continue\n",
    "        pred_c = pred == c\n",
    "        intersection = np.logical_and(pred_c, label_c).sum()\n",
    "        union = np.logical_or(pred_c, label_c).sum()\n",
    "        if union != 0:\n",
    "            ious.append(intersection / union)\n",
    "        else:\n",
    "            ious.append(1)\n",
    "    return ious if ious else [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3442373434954994"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "np.nanmean(np.array(compute_ious(preds.numpy(), targs.numpy(), classes=[0,1,2,3], only_present=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def compute_iou_batch(outputs, labels, classes=None):\n",
    "    \"\"\"computes mean iou for a batch of ground truth masks and predicted masks\"\"\"\n",
    "    ious = []\n",
    "    outputs, labels = outputs.cpu(), labels.cpu()\n",
    "    preds = np.copy(outputs) # copy is imp\n",
    "    labels = np.array(labels) # tensor to np\n",
    "    for pred, label in zip(preds, labels):\n",
    "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
    "    iou = np.nanmean(ious)\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4798260968741874"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "compute_iou_batch(preds, targs, classes=[0,1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def dice(\n",
    "    outputs: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    eps: float = 1e-7,\n",
    "    threshold: float = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Computes the binary dice metric\n",
    "    Args:\n",
    "        outputs (list):  A list of predicted elements\n",
    "        targets (list): A list of elements that are to be predicted\n",
    "        eps (float): epsilon\n",
    "        threshold (float): threshold for outputs binarization\n",
    "    Returns:\n",
    "        double:  Dice score\n",
    "    \"\"\"\n",
    "    outputs = F.sigmoid(outputs)\n",
    "\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold).float()\n",
    "\n",
    "    intersection = torch.sum(targets * outputs)\n",
    "    union = torch.sum(targets) + torch.sum(outputs)\n",
    "    dice = 2 * intersection / (union + eps)\n",
    "\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here there'are some functions used by the pure pytorch solution from a kaggle kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def metric(probability, truth, threshold=0.5, reduction='none'):\n",
    "    \"\"\"\n",
    "    Calculates dice of positive and negative images seperately\n",
    "    `probability` and `truth` must be `torch.Tensors`.\n",
    "    \"\"\"\n",
    "    if isinstance(truth, tuple):\n",
    "        truth = truth[0]\n",
    "    batch_size = len(truth)\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > 0.5).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice #, dice_neg, dice_pos, num_neg, num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage([[0.0166],\n",
       "        [0.0773],\n",
       "        [0.0239],\n",
       "        [0.0171],\n",
       "        [0.1802],\n",
       "        [0.0207],\n",
       "        [0.0224],\n",
       "        [0.0933],\n",
       "        [0.0217],\n",
       "        [0.0172],\n",
       "        [0.0175],\n",
       "        [0.0069],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000],\n",
       "        [0.0000]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "metric(preds, targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def predict(X, threshold):\n",
    "    \"\"\"X is sigmoid output of the model\"\"\"\n",
    "    X_p = np.copy(X)\n",
    "    preds = (X_p > threshold).astype('uint8')\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Meter:\n",
    "    \"\"\"A meter to keep track of iou and dice scores throughout an epoch\"\"\"\n",
    "    def __init__(self, phase, epoch):\n",
    "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
    "        self.base_dice_scores = []\n",
    "        self.dice_neg_scores = []\n",
    "        self.dice_pos_scores = []\n",
    "        self.iou_scores = []\n",
    "\n",
    "    def update(self, targets, outputs):\n",
    "        probs = torch.sigmoid(outputs)\n",
    "        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n",
    "        \n",
    "        self.base_dice_scores.extend(dice.tolist())\n",
    "        self.dice_pos_scores.extend(dice_pos.tolist())\n",
    "        self.dice_neg_scores.extend(dice_neg.tolist())\n",
    "        \n",
    "        preds = predict(probs, self.base_threshold)\n",
    "        \n",
    "        iou = compute_iou_batch(preds, targets, classes=[1])\n",
    "        self.iou_scores.append(iou)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        \"\"\"\n",
    "        Calc the mean of dices metrics (dice, dice_neg, dice_pos)\n",
    "        and IoU mean.\n",
    "        \n",
    "        Returns: \n",
    "            `dices` as list of means `[dice, dice_neg, dice_pos]`,\n",
    "            `iou` as mean of IoUs\n",
    "        \"\"\"\n",
    "        dice     = np.nanmean(self.base_dice_scores)\n",
    "        dice_neg = np.nanmean(self.dice_neg_scores)\n",
    "        dice_pos = np.nanmean(self.dice_pos_scores)\n",
    "        \n",
    "        dices = [dice, dice_neg, dice_pos]\n",
    "        iou = np.nanmean(self.iou_scores)\n",
    "        \n",
    "        return dices, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(Meter.get_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
    "    \"\"\"logging the metrics at the end of an epoch\"\"\"\n",
    "    dices, iou = meter.get_metrics()\n",
    "    dice, dice_neg, dice_pos = dices\n",
    "    print(f\"Loss: {epoch_loss:.4f} | IoU: {iou:.4f} | dice: {dice:.4f} | dice_neg: {dice_neg:.4f} | dice_pos: {dice_pos:.4f}\")\n",
    "    return dice, iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_metadata.ipynb.\n",
      "Converted 02_masks.ipynb.\n",
      "Converted 03_datasets.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_loss.ipynb.\n",
      "Converted 07_trainer.ipynb.\n",
      "Converted 08_predict.ipynb.\n",
      "Converted 09_visualize.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
