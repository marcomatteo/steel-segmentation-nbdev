{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#missing\n",
    "!git clone https://github.com/marcomatteo/steel_segmentation.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#missing\n",
    "!pip install -e steel_segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "> A collection of Metrics used in the segmentation models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/marcomatteo/steel_segmentation/blob/master/nbs/05_metrics.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from steel_segmentation.metadata import *\n",
    "from steel_segmentation.masks import *\n",
    "from steel_segmentation.datasets import *\n",
    "from steel_segmentation.dataloaders import *\n",
    "\n",
    "import fastai\n",
    "from fastai.vision.all import *\n",
    "from fastcore.foundation import *\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section there are all the metric that can be used to evaluate the performances of the segmentation models trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([20, 3, 256, 256]), torch.Size([20, 4, 256, 256]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "device = torch.device(\"cpu\")\n",
    "dls = get_segmnt_dls(bs=20, size=(256, 256))\n",
    "x, targs = dls.train.one_batch()\n",
    "x.shape, targs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "x = x.cpu()\n",
    "x.device, targs.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 256, 256])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "model = smp.Unet(\"resnet18\", \n",
    "                 encoder_weights=\"imagenet\", \n",
    "                 classes=4, \n",
    "                 activation=None).to(device)\n",
    "logits = model(x)\n",
    "preds = (torch.sigmoid(logits) > 0.5).float()\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cpu'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "logits.device, preds.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code comes from the fastai docs to test properly the metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For testing: a fake learner and a metric that isn't an average\n",
    "@delegates()\n",
    "class TstLearner(Learner):\n",
    "    def __init__(self,dls=None,model=None,**kwargs): self.pred,self.xb,self.yb = None,None,None\n",
    "        \n",
    "#Go through a fake cycle with various batch sizes and computes the value of met\n",
    "def compute_val(met, pred, y):\n",
    "    met.reset()\n",
    "    vals = [0,6,15,20]\n",
    "    learn = TstLearner()\n",
    "    for i in range(3):\n",
    "        learn.pred = pred[vals[i]:vals[i+1]]\n",
    "        learn.yb = ( y[vals[i]:vals[i+1]], )\n",
    "        met.accumulate(learn)\n",
    "    return met.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class ModDiceMulti(Metric):\n",
    "    \"Averaged Dice metric (Macro F1) for multiclass target in segmentation\"\n",
    "\n",
    "    def __init__(self, axis=1): self.axis = axis\n",
    "    def reset(self): self.inter, self.union = {}, {}\n",
    "\n",
    "    def accumulate(self, learn):\n",
    "        pred = learn.pred.argmax(dim=self.axis)\n",
    "        y = learn.yb[0]\n",
    "        \n",
    "        # Added to deal with 4-channels masks\n",
    "        if pred.shape != y.shape:\n",
    "            y = y.argmax(dim=self.axis)\n",
    "            \n",
    "        pred, targ = flatten_check(pred, y)\n",
    "        for c in range(learn.pred.shape[self.axis]):\n",
    "            p = torch.where(pred == c, 1, 0)\n",
    "            t = torch.where(targ == c, 1, 0)\n",
    "            p, t = TensorBase(p), TensorBase(t)\n",
    "            c_inter = (p*t).float().sum().item()\n",
    "            c_union = (p+t).float().sum().item()\n",
    "            if c in self.inter:\n",
    "                self.inter[c] += c_inter\n",
    "                self.union[c] += c_union\n",
    "            else:\n",
    "                self.inter[c] = c_inter\n",
    "                self.union[c] = c_union\n",
    "\n",
    "    @property\n",
    "    def value(self):\n",
    "        binary_dice_scores = np.array([])\n",
    "        for c in self.inter:\n",
    "            binary_dice_scores = np.append(\n",
    "                binary_dice_scores, \n",
    "                2.*self.inter[c]/self.union[c] if self.union[c] > 0 else np.nan)\n",
    "        self.binary_dice_scores = binary_dice_scores\n",
    "        return np.nanmean(binary_dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_obj = ModDiceMulti()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2136215772421966"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "compute_val(dice_obj, pred=preds, y=targs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For test purpose, we create a tensor `x1`, as a prediction for the first channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1a = torch.ones(20,1,1,1)\n",
    "x1b = torch.clone(x1a)*0.5\n",
    "x1c = torch.clone(x1a)*0.3\n",
    "x1d = torch.clone(x1a)*0.1\n",
    "\n",
    "x1 = torch.cat((x1a,x1b,x1c,x1d),dim=1)   # Prediction: 20x4\n",
    "x1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When target is a flatten mask, used by fastai segmentation models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2 = torch.zeros(20,1,1)  # Target: 20xClass0\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the target is a 4-channels mask, used by pytorch segmentation models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2chs = torch.zeros(20,4,1,1)  # Target: 20xClass0\n",
    "x2chs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test of `DiceMulti` into a simulated training with `compute_val` and a test Learner with `TstLearner`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice metric = 1\n",
    "test_eq(compute_val(dice_obj, x1, x2), 1.)\n",
    "test_eq(compute_val(dice_obj, x1, x2chs), 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice metric = 0, Target: 20xClass1\n",
    "x2 = torch.ones(20,1,1)  \n",
    "test_eq(compute_val(dice_obj, x1, x2), 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2_ch0 = torch.zeros(20,1,1,1)\n",
    "x2_ch1 = torch.ones(20,1,1,1)\n",
    "x2_ch2 = torch.zeros(20,1,1,1)\n",
    "x2_ch3 = torch.zeros(20,1,1,1)\n",
    "x2chs = torch.cat((x2_ch0, x2_ch1, x2_ch2, x2_ch3),dim=1)\n",
    "\n",
    "test_eq(compute_val(dice_obj, x1, x2chs), 0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different scenario with a multiclass batch:\n",
    "- Class0 x 10\n",
    "- Class1 x 4\n",
    "- Class2 x 3\n",
    "- Class4 x 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2a = torch.zeros(10,1,1)\n",
    "x2b = torch.ones(4,1,1)\n",
    "x2c = torch.ones(3,1,1) * 2\n",
    "x2d = torch.ones(3,1,1) * 3\n",
    "\n",
    "x2 = torch.cat((x2a,x2b,x2c,x2d),dim=0)   # Target: 10xClass0, 4xClass1, 3xClass2, 3xClass4\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4, 1, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target: 10xClass0, 4xClass1, 3xClass2, 3xClass4\n",
    "batch_sizes = [10, 4, 3, 3]\n",
    "\n",
    "x2_chs = [torch.zeros(n, 4, 1, 1) for i, n in enumerate(batch_sizes)]\n",
    "for i, x2_ch in enumerate(x2_chs):\n",
    "    x2_ch[:, i] = 1\n",
    "\n",
    "x2chs = torch.cat(x2_chs, dim=0)\n",
    "x2chs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value to be tested\n",
    "computed_dice = compute_val(dice_obj, x1, x2)\n",
    "computed_dice_chs = compute_val(dice_obj, x1, x2chs)\n",
    "test_eq(computed_dice,computed_dice_chs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dice: 2*TP/(2*TP+FP+FN)\n",
    "dice1 = (2*10)/(2*10+4+3+3)              \n",
    "dice2 = 0\n",
    "dice3 = 0\n",
    "dice4 = 0\n",
    "\n",
    "# Dice metric = 0.1666\n",
    "test_eq(computed_dice, (dice1+dice2+dice3+dice4)/4)\n",
    "test_eq(computed_dice_chs, (dice1+dice2+dice3+dice4)/4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle Dice metric\n",
    "The competition \"Evaluation\" metric is defined as:\n",
    "\n",
    "> This competition is evaluated on the mean Dice coefficient. The Dice coefficient can be used to compare the pixel-wise agreement between a predicted segmentation and its corresponding ground truth. The formula is given by:\n",
    "\n",
    "$$\n",
    "J(A,B) = \\frac{2 * |A \\cap B|}{|A| \\cup |B|}\n",
    "$$\n",
    "\n",
    "> where X is the predicted set of pixels and Y is the ground truth. The Dice coefficient is defined to be 1 when both X and Y are empty. The leaderboard score is the mean of the Dice coefficients for each <ImageId, ClassId> pair in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7500000005\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = [0,6,15,20]\n",
    "intersect, union = {}, {}\n",
    "\n",
    "for j in range(3):\n",
    "    pred = x1[vals[j]:vals[j+1]].clone()\n",
    "    targ = ( x2[vals[j]:vals[j+1]].clone(), )\n",
    "    targ = targ[0]\n",
    "    eps = 1e-9\n",
    "    # pred.shape, targ.shape\n",
    "\n",
    "    if pred.shape == targ.shape:\n",
    "        targ = targ.argmax(dim=1)\n",
    "    n, c = targ.shape[0], pred.shape[1]\n",
    "    # n, c\n",
    "\n",
    "    pred = pred.argmax(dim=1).view(n, -1)\n",
    "    targ = targ.view(n, -1)\n",
    "    # pred.shape, targ.shape\n",
    "    # pred.max(), targ.max()\n",
    "    for i in range(0, c):\n",
    "        p = torch.where(pred == i, 1, 0)\n",
    "        t = torch.where(targ == i, 1, 0)\n",
    "        p, t = TensorBase(p), TensorBase(t)\n",
    "        c_inter = (p*t).sum(-1).float()#.item()\n",
    "        c_union = (p+t).sum(-1).float()#.item()\n",
    "        if i in intersect:\n",
    "            intersect[i] = torch.cat([intersect[i], c_inter], dim=0)\n",
    "            union[i]     = torch.cat([union[i], c_union], dim=0)\n",
    "        else:\n",
    "            intersect[i] = c_inter\n",
    "            union[i]     = c_union\n",
    "\n",
    "binary_dice_scores = np.array([])\n",
    "for c in intersect.keys():\n",
    "    cond = union[c] == 0\n",
    "    val = 2.*(intersect[c]+eps)/(union[c]+eps)\n",
    "    val[cond] = 1\n",
    "    binary_dice_scores = np.append(binary_dice_scores, val)\n",
    "\n",
    "num = 4\n",
    "fig, axs = plt.subplots(num, 1, sharex=True)\n",
    "for i in range(num):\n",
    "    axs[i].plot(binary_dice_scores[(i*20):((i*20)+20)])\n",
    "    axs[i].set_title(i, loc='right', y=.6, pad=-7.)\n",
    "print(binary_dice_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class KaggleDice(Metric):\n",
    "    \"\"\"\n",
    "    Multi-class Dice used in Severstal comp, \n",
    "    is 1 when prediction and mask are empty\n",
    "    \"\"\"\n",
    "    def __init__(self, axis=1, eps=1e-9): self.axis, self.eps = axis, eps\n",
    "    def reset(self): self.inter, self.union = {}, {}\n",
    "    \n",
    "    def accumulate(self, learn):\n",
    "        y = learn.yb[0]\n",
    "        preds = learn.pred\n",
    "        \n",
    "        if preds.shape == y.shape:\n",
    "            y = y.argmax(dim=self.axis)\n",
    "            \n",
    "        n, c = y.shape[0], preds.shape[self.axis]\n",
    "        \n",
    "        preds = preds.argmax(dim=self.axis).view(n, -1)\n",
    "        targs = y.view(n, -1)\n",
    "        \n",
    "#         pred, targ = flatten_check(preds, targs)\n",
    "        for i in range(0, c):\n",
    "            p = torch.where(preds == i, 1, 0)\n",
    "            t = torch.where(targs == i, 1, 0)\n",
    "            \n",
    "            p, t = TensorBase(p), TensorBase(t)\n",
    "            \n",
    "            c_inter = (p*t).sum(-1).float().cpu()#.item()\n",
    "            c_union = (p+t).sum(-1).float().cpu()#.item()\n",
    "            if i in self.inter:\n",
    "                self.inter[i] = torch.cat([self.inter[i], c_inter], dim=0)\n",
    "                self.union[i] = torch.cat([self.union[i], c_union], dim=0)\n",
    "            else:\n",
    "                self.inter[i] = c_inter\n",
    "                self.union[i] = c_union\n",
    "                    \n",
    "    @property\n",
    "    def value(self):\n",
    "        binary_dice_scores = np.array([])\n",
    "        for c in range(len(self.inter)):\n",
    "            cond = self.union[c] == 0\n",
    "            val = 2.*(self.inter[c]+self.eps)/(self.union[c]+self.eps)\n",
    "            val[cond] = 1\n",
    "            binary_dice_scores = np.append(binary_dice_scores, val.numpy())\n",
    "        self.binary_dice_scores = binary_dice_scores\n",
    "        return np.nanmean(binary_dice_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_kaggle_obj = KaggleDice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2071837278086755"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# missing\n",
    "compute_val(dice_kaggle_obj, pred=preds, y=targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_kaggle_dice = compute_val(dice_kaggle_obj, x1, x2)\n",
    "computed_kaggle_dice_chs = compute_val(dice_kaggle_obj, x1, x2chs)\n",
    "\n",
    "test_close(computed_kaggle_dice, binary_dice_scores.mean())\n",
    "test_eq(computed_kaggle_dice, computed_kaggle_dice_chs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative metric for Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def dice_kaggle(pred: Tensor, targ: Tensor, iou:bool=False, eps:float=1e-8):\n",
    "    \"\"\"\n",
    "    The metric of the competition, \n",
    "    if there's no defect in `targ` and no defects in `pred`: dice=1.\n",
    "    \"\"\"\n",
    "    n, c = targ.shape[0], pred.shape[1]\n",
    "    \n",
    "    if pred.shape == targ.shape:\n",
    "        targ = targ.argmax(dim=1)\n",
    "    \n",
    "    pred = pred.argmax(dim=1).view(n, -1)\n",
    "    targ = targ.view(n, -1)\n",
    "\n",
    "    intersect_list, union_list = [], []\n",
    "    for i in range(c):\n",
    "        inp, trgs = TensorBase(pred), TensorBase(targ)\n",
    "        \n",
    "        inter = ((inp == i) & (trgs == i)).sum(-1).float()\n",
    "        un = ((inp == i).sum(-1) + (trgs == i).sum(-1))\n",
    "        \n",
    "        intersect_list.append(inter)\n",
    "        union_list.append(un)\n",
    "\n",
    "    intersect = torch.stack(intersect_list)\n",
    "    union = torch.stack(union_list)\n",
    "\n",
    "    if not iou:\n",
    "        metric = ((2.0 * intersect + eps) / (union + eps))\n",
    "    else:\n",
    "        metric = ((intersect + eps) / (union - intersect + eps))\n",
    "        \n",
    "    return metric.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing\n",
    "tst = AccumMetric(dice_kaggle, flatten=False, dim_argmax=0)\n",
    "test_close(compute_val(tst, preds, targs), dice_kaggle(preds, targs))\n",
    "\n",
    "test_close(compute_val(dice_kaggle_obj, preds, targs), \n",
    "           compute_val(            tst, preds, targs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst = AccumMetric(dice_kaggle, flatten=False)\n",
    "test_close(compute_val(tst, x1, x2), dice_kaggle(x1, x2))\n",
    "\n",
    "tst = AccumMetric(dice_kaggle, flatten=False, dim_argmax=0)\n",
    "test_close(compute_val(tst, x1, x2chs), dice_kaggle(x1, x2chs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(outputs:Tensor, targets:Tensor, eps:float=1e-7, threshold:float=None):\n",
    "    \"\"\"\n",
    "    Computes the binary dice metric\n",
    "    Args:\n",
    "        outputs (list):  A list of predicted elements\n",
    "        targets (list): A list of elements that are to be predicted\n",
    "        eps (float): epsilon\n",
    "        threshold (float): threshold for outputs binarization\n",
    "    Returns:\n",
    "        double:  Dice score\n",
    "    \"\"\"\n",
    "    outputs = F.sigmoid(outputs)\n",
    "\n",
    "    if threshold is not None:\n",
    "        outputs = (outputs > threshold).float()\n",
    "\n",
    "    intersection = torch.sum(targets * outputs)\n",
    "    union = torch.sum(targets) + torch.sum(outputs)\n",
    "    dice = 2 * intersection / (union + eps)\n",
    "\n",
    "    return dice\n",
    "\n",
    "def metric(probability, truth, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculates dice of positive and negative images seperately\n",
    "    `probability` and `truth` must be `torch.Tensors`.\n",
    "    \"\"\"\n",
    "    if isinstance(truth, tuple):\n",
    "        truth = truth[0]\n",
    "        \n",
    "    batch_size = len(truth)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > 0.5).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        num_neg = len(neg_index)\n",
    "        num_pos = len(pos_index)\n",
    "\n",
    "    return dice, dice_neg, dice_pos, num_neg, num_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorImage(0.0072)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "dices, _, _, _, _= metric(preds, targs)\n",
    "dices.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def metric(probability, truth, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculates dice of positive and negative images seperately\n",
    "    `probability` and `truth` must be `torch.Tensors`.\n",
    "    \"\"\"\n",
    "    #if isinstance(truth, tuple):\n",
    "    #    truth = truth[0]\n",
    "    base_dice_scores, dice_pos_scores, dice_neg_scores = [], [], []\n",
    "    \n",
    "    batch_size = len(truth)\n",
    "    with torch.no_grad():\n",
    "        probability = probability.view(batch_size, -1)\n",
    "        truth = truth.view(batch_size, -1)\n",
    "        assert(probability.shape == truth.shape)\n",
    "\n",
    "        p = (probability > threshold).float()\n",
    "        t = (truth > 0.5).float()\n",
    "\n",
    "        t_sum = t.sum(-1)\n",
    "        p_sum = p.sum(-1)\n",
    "        neg_index = torch.nonzero(t_sum == 0)\n",
    "        pos_index = torch.nonzero(t_sum >= 1)\n",
    "\n",
    "        dice_neg = (p_sum == 0).float()\n",
    "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))\n",
    "\n",
    "        dice_neg = dice_neg[neg_index]\n",
    "        dice_pos = dice_pos[pos_index]\n",
    "        dice = torch.cat([dice_pos, dice_neg])\n",
    "        \n",
    "        base_dice_scores.extend(dice.tolist())\n",
    "        dice_pos_scores.extend(dice_pos.tolist())\n",
    "        dice_neg_scores.extend(dice_neg.tolist())\n",
    "        \n",
    "        dice     = np.nanmean(base_dice_scores)\n",
    "        dice_neg = np.nanmean(dice_neg_scores)\n",
    "        dice_pos = np.nanmean(dice_pos_scores)\n",
    "\n",
    "    return dice, dice_neg, dice_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.007218837807886303, 0.0, 0.02887535123154521)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "metric(preds, targs, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.007218837807886303, 0.0, 0.02887535123154521)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing\n",
    "m = AccumMetric(metric, flatten=False, dim_argmax=0)\n",
    "compute_val(m, pred=preds, y=targs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5, nan, 0.5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = AccumMetric(metric, flatten=False, dim_argmax=0)\n",
    "compute_val(m, pred=x1, y=x2chs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def epoch_log(epoch_loss, meter):\n",
    "    \"\"\"logging the metrics at the end of an epoch\"\"\"\n",
    "    dices = meter.get_metrics()\n",
    "    dice, dice_neg, dice_pos = dices\n",
    "    print(f\"Loss: {epoch_loss:.4f} | dice: {dice:.4f} | dice_neg: {dice_neg:.4f} | dice_pos: {dice_pos:.4f}\")\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.0000 | dice: 0.5260 | dice_neg: nan | dice_pos: 0.5260\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5259531036019325"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_log(0.0, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 01_metadata.ipynb.\n",
      "Converted 02_masks.ipynb.\n",
      "Converted 03_datasets.ipynb.\n",
      "Converted 04_dataloaders.ipynb.\n",
      "Converted 05_metrics.ipynb.\n",
      "Converted 06_loss.ipynb.\n",
      "Converted 07_trainer.ipynb.\n",
      "Converted 08_predict.ipynb.\n",
      "Converted 09_visualize.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
