{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp models.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "widespread-offense",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "> Deep Learning modules with Fastai/Pytorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-harrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-degree",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "from steel_segmentation.core import *\n",
    "from steel_segmentation.data import *\n",
    "from steel_segmentation.preprocessing import *\n",
    "from steel_segmentation.models.dls import *\n",
    "from steel_segmentation.models.metrics import *\n",
    "\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    from fastai.vision.all import *\n",
    "    import fastai\n",
    "from fastcore.foundation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-peninsula",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hide\n",
    "only_imgs = [\"0a1cade03.jpg\", \"bca4ae758.jpg\", \"988cf521f.jpg\", \"b6a257b28.jpg\",\n",
    "             \"b2ad335bf.jpg\", \"72aaba8ad.jpg\", \"f383950e8.jpg\"]\n",
    "train = train[train[\"ImageId\"].isin(only_imgs)].copy()\n",
    "train_all = train_all[train_all[\"ImageId\"].isin(only_imgs)].copy()\n",
    "train_multi = train_multi[train_multi[\"ImageId\"].isin(only_imgs)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broke-kansas",
   "metadata": {},
   "source": [
    "First we create a classification model to get an encoder that know how to classify defects pixels.\n",
    "Then, we build a UNet from the trained encoder and train a segmentation model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "toxic-crime",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "models_dir = path.parent / \"models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing\n",
    "models_dir.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-record",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informed-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "class_metrics = [accuracy_multi, PrecisionMulti(), RecallMulti()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bronze-poland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_classifier_learner(bs:int, arch=resnet18, metrics=class_metrics, toload:str=None):\n",
    "    \"\"\"Get a classification `Learner`\"\"\"\n",
    "    dls = get_classification_dls(bs)\n",
    "    arch = partial(arch, pretrained=True)\n",
    "    learner = cnn_learner(dls=dls, arch=arch, metrics=metrics, pretrained=True)\n",
    "    \n",
    "    if toload and toload.endswith(\".pth\"):\n",
    "        return learner.load(models_dir/toload)\n",
    "    \n",
    "    return learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-sleeping",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4\n",
    "class_learner = get_classifier_learner(bs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tough-worse",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exports\n",
    "seg_metrics = [DiceMulti(), dice_kaggle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4 \n",
    "szs = (128, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-bristol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_segmentation_learner(bs: int, szs, arch=resnet18, metrics=seg_metrics, toload: str = None):\n",
    "    dls = get_segmentation_dls_from_df(train_multi, bs, szs)\n",
    "    segmentation_learner = unet_learner(\n",
    "        dls=dls, arch=arch, metrics=metrics, pretrained=True)\n",
    "    if toload and toload.endswith('.pt'):\n",
    "        encoder_path = models_dir / \"ResNet18-2_class.pt\"\n",
    "        segmentation_learner.model[0].load_state_dict(\n",
    "            torch.load(encoder_path), strict=True)\n",
    "    return segmentation_learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporated-discovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_learn = get_segmentation_learner(bs, szs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-valve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_core.ipynb.\n",
      "Converted 01_data.ipynb.\n",
      "Converted 02_preprocessing.ipynb.\n",
      "Converted 03_models.dls.ipynb.\n",
      "Converted 04_model.metrics.ipynb.\n",
      "Converted 05_models.module.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "# hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
