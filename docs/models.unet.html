---

title: Unet Architecture


keywords: fastai
sidebar: home_sidebar

summary: "A deep dive into Unet architecture in Pytorch."
description: "A deep dive into Unet architecture in Pytorch."
nb_path: "nbs/05_models.unet.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: nbs/05_models.unet.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Unet architecture from the <a href="https://github.com/qubvel/segmentation_models.pytorch">segmentation_models.pytorch</a> repository.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Model" class="doc_header"><code>class</code> <code>Model</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L20" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Model</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Custom <code>nn.Module</code> class with <code>kaiming_normal_</code> initialization. This class look into <code>self.modules</code> and if it's a <code>nn.BatchNorm2d</code> init with 1 the weights and 0 the biases.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Conv2dReLU" class="doc_header"><code>class</code> <code>Conv2dReLU</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L35" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Conv2dReLU</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>kernel_size</code></strong>, <strong><code>padding</code></strong>=<em><code>0</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>use_batchnorm</code></strong>=<em><code>True</code></em>, <strong>**<code>batchnorm_params</code></strong>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Conv2dReLU.__init__" class="doc_header"><code>Conv2dReLU.__init__</code><a href="__main__.py#L4" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Conv2dReLU.__init__</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>kernel_size</code></strong>, <strong><code>padding</code></strong>=<em><code>0</code></em>, <strong><code>stride</code></strong>=<em><code>1</code></em>, <strong><code>use_batchnorm</code></strong>=<em><code>True</code></em>, <strong>**<code>batchnorm_params</code></strong>)</p>
</blockquote>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">gv</span><span class="p">(</span><span class="s1">&#39;&#39;&#39;Conv2d-&gt;BatchNorm-&gt;ReLU&#39;&#39;&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_svg output_subarea output_execute_result">
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN"
 "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<!-- Generated by graphviz version 2.40.1 (20161225.0304)
 -->
<!-- Title: G Pages: 1 -->
<svg width="332pt" height="44pt"
 viewBox="0.00 0.00 332.18 44.00" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink">
<g id="graph0" class="graph" transform="scale(1 1) rotate(0) translate(4 40)">
<title>G</title>
<polygon fill="#ffffff" stroke="transparent" points="-4,4 -4,-40 328.1776,-40 328.1776,4 -4,4"/>
<!-- Conv2d -->
<g id="node1" class="node">
<title>Conv2d</title>
<ellipse fill="none" stroke="#000000" cx="39.6465" cy="-18" rx="39.7935" ry="18"/>
<text text-anchor="middle" x="39.6465" y="-14.3" font-family="Times,serif" font-size="14.00" fill="#000000">Conv2d</text>
</g>
<!-- BatchNorm -->
<g id="node2" class="node">
<title>BatchNorm</title>
<ellipse fill="none" stroke="#000000" cx="168.5882" cy="-18" rx="53.0913" ry="18"/>
<text text-anchor="middle" x="168.5882" y="-14.3" font-family="Times,serif" font-size="14.00" fill="#000000">BatchNorm</text>
</g>
<!-- Conv2d&#45;&gt;BatchNorm -->
<g id="edge1" class="edge">
<title>Conv2d&#45;&gt;BatchNorm</title>
<path fill="none" stroke="#000000" d="M79.3854,-18C87.4695,-18 96.1651,-18 104.8432,-18"/>
<polygon fill="#000000" stroke="#000000" points="104.9848,-21.5001 114.9847,-18 104.9847,-14.5001 104.9848,-21.5001"/>
</g>
<!-- ReLU -->
<g id="node3" class="node">
<title>ReLU</title>
<ellipse fill="none" stroke="#000000" cx="291.0306" cy="-18" rx="33.2948" ry="18"/>
<text text-anchor="middle" x="291.0306" y="-14.3" font-family="Times,serif" font-size="14.00" fill="#000000">ReLU</text>
</g>
<!-- BatchNorm&#45;&gt;ReLU -->
<g id="edge2" class="edge">
<title>BatchNorm&#45;&gt;ReLU</title>
<path fill="none" stroke="#000000" d="M221.937,-18C230.4558,-18 239.1814,-18 247.4391,-18"/>
<polygon fill="#000000" stroke="#000000" points="247.598,-21.5001 257.5979,-18 247.5979,-14.5001 247.598,-21.5001"/>
</g>
</g>
</svg>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DecoderBlock" class="doc_header"><code>class</code> <code>DecoderBlock</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L57" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DecoderBlock</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>use_batchnorm</code></strong>=<em><code>True</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Up sample the inputs by a <code>scale_factor</code> of 2 with <code>'nearest'</code>, if a <code>skip</code> connection is provided then concatenates with the inputs and then do a double <a href="/steel_segmentation/models.unet.html#Conv2dReLU"><code>Conv2dReLU</code></a>.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="CenterBlock" class="doc_header"><code>class</code> <code>CenterBlock</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L76" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>CenterBlock</code>(<strong><code>in_channels</code></strong>, <strong><code>out_channels</code></strong>, <strong><code>use_batchnorm</code></strong>=<em><code>True</code></em>) :: <a href="/steel_segmentation/models.unet.html#DecoderBlock"><code>DecoderBlock</code></a></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>A double <a href="/steel_segmentation/models.unet.html#Conv2dReLU"><code>Conv2dReLU</code></a> without up sampling.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="EncoderDecoder" class="doc_header"><code>class</code> <code>EncoderDecoder</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L82" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>EncoderDecoder</code>(<strong><code>encoder</code></strong>, <strong><code>decoder</code></strong>, <strong><code>activation</code></strong>) :: <a href="/steel_segmentation/models.unet.html#Model"><code>Model</code></a></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EncoderDecoder.__init__" class="doc_header"><code>EncoderDecoder.__init__</code><a href="__main__.py#L4" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EncoderDecoder.__init__</code>(<strong><code>encoder</code></strong>, <strong><code>decoder</code></strong>, <strong><code>activation</code></strong>)</p>
</blockquote>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EncoderDecoder.forward" class="doc_header"><code>EncoderDecoder.forward</code><a href="__main__.py#L19" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EncoderDecoder.forward</code>(<strong><code>x</code></strong>)</p>
</blockquote>
<p>Sequentially pass <code>x</code> trough model's <code>encoder</code> and <code>decoder</code> (return logits!)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="EncoderDecoder.predict" class="doc_header"><code>EncoderDecoder.predict</code><a href="__main__.py#L25" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>EncoderDecoder.predict</code>(<strong><code>x</code></strong>)</p>
</blockquote>
<p>Inference method. Switch model to <code>eval</code> mode, call <code>.forward(x)</code>
and apply activation function (if activation is not <code>None</code>) with <code>torch.no_grad()</code></p>
<p>Args:
    x: 4D torch tensor with shape (batch_size, channels, height, width)</p>
<p>Return:
    prediction: 4D torch tensor with shape (batch_size, classes, height, width)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="UnetDecoder" class="doc_header"><code>class</code> <code>UnetDecoder</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L128" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>UnetDecoder</code>(<strong><code>encoder_channels</code></strong>, <strong><code>decoder_channels</code></strong>=<em><code>(256, 128, 64, 32, 16)</code></em>, <strong><code>final_channels</code></strong>=<em><code>1</code></em>, <strong><code>use_batchnorm</code></strong>=<em><code>True</code></em>, <strong><code>center</code></strong>=<em><code>False</code></em>) :: <a href="/steel_segmentation/models.unet.html#Model"><code>Model</code></a></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Decoder part of a Unet.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="ResNetEncoder" class="doc_header"><code>class</code> <code>ResNetEncoder</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L192" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>ResNetEncoder</code>(<strong>*<code>args</code></strong>, <strong>**<code>kwargs</code></strong>) :: <code>ResNet</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Encoder part of a Unet.</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="preprocess_input" class="doc_header"><code>preprocess_input</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L275" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>preprocess_input</code>(<strong><code>x</code></strong>, <strong><code>mean</code></strong>=<em><code>None</code></em>, <strong><code>std</code></strong>=<em><code>None</code></em>, <strong><code>input_space</code></strong>=<em><code>'RGB'</code></em>, <strong><code>input_range</code></strong>=<em><code>None</code></em>, <strong>**<code>kwargs</code></strong>)</p>
</blockquote>
<p>Preprocessing the <code>x</code> inputs with normalization.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_encoder" class="doc_header"><code>get_encoder</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L295" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_encoder</code>(<strong><code>name</code></strong>, <strong><code>encoder_weights</code></strong>=<em><code>None</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_encoder_names" class="doc_header"><code>get_encoder_names</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L307" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_encoder_names</code>()</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="get_preprocessing_fn" class="doc_header"><code>get_preprocessing_fn</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L311" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>get_preprocessing_fn</code>(<strong><code>encoder_name</code></strong>, <strong><code>pretrained</code></strong>=<em><code>'imagenet'</code></em>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="Unet" class="doc_header"><code>class</code> <code>Unet</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/models/unet.py#L326" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>Unet</code>(<strong><code>encoder_name</code></strong>=<em><code>'resnet34'</code></em>, <strong><code>encoder_weights</code></strong>=<em><code>'imagenet'</code></em>, <strong><code>decoder_use_batchnorm</code></strong>=<em><code>True</code></em>, <strong><code>decoder_channels</code></strong>=<em><code>(256, 128, 64, 32, 16)</code></em>, <strong><code>classes</code></strong>=<em><code>1</code></em>, <strong><code>activation</code></strong>=<em><code>'sigmoid'</code></em>, <strong><code>center</code></strong>=<em><code>False</code></em>) :: <a href="/steel_segmentation/models.unet.html#EncoderDecoder"><code>EncoderDecoder</code></a></p>
</blockquote>
<p>Unet_ is a fully convolution neural network for image semantic segmentation</p>
<p>Args:
    encoder_name: name of classification model (without last dense layers) used as feature
        extractor to build segmentation model.
    encoder_weights: one of <code>None</code> (random initialization), <code>imagenet</code> (pre-training on ImageNet).
    decoder_channels: list of numbers of <code>Conv2D</code> layer filters in decoder blocks
    decoder_use_batchnorm: if <code>True</code>, <code>BatchNormalisation</code> layer between <code>Conv2D</code> and <code>Activation</code> layers
        is used.
    classes: a number of classes for output (output shape - <code>(batch, classes, h, w)</code>).
    activation: activation function used in <code>.predict(x)</code> method for inference.
        One of [<code>sigmoid</code>, <code>softmax</code>, callable, None]
    center: if <code>True</code> add <code>Conv2dReLU</code> block on encoder head (useful for VGG models)</p>
<p>Returns:
    <code>torch.nn.Module</code>: <strong>Unet</strong></p>
<p>Paper:
<a href="https://arxiv.org/pdf/1505.04597">https://arxiv.org/pdf/1505.04597</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="Unet.__init__" class="doc_header"><code>Unet.__init__</code><a href="__main__.py#L25" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>Unet.__init__</code>(<strong><code>encoder_name</code></strong>=<em><code>'resnet34'</code></em>, <strong><code>encoder_weights</code></strong>=<em><code>'imagenet'</code></em>, <strong><code>decoder_use_batchnorm</code></strong>=<em><code>True</code></em>, <strong><code>decoder_channels</code></strong>=<em><code>(256, 128, 64, 32, 16)</code></em>, <strong><code>classes</code></strong>=<em><code>1</code></em>, <strong><code>activation</code></strong>=<em><code>'sigmoid'</code></em>, <strong><code>center</code></strong>=<em><code>False</code></em>)</p>
</blockquote>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

