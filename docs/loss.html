---

title: Loss functions


keywords: fastai
sidebar: home_sidebar

summary: "Lovasz-Softmax and Jaccard hinge loss in PyTorch"
description: "Lovasz-Softmax and Jaccard hinge loss in PyTorch"
nb_path: "dev_nbs/08_loss.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: dev_nbs/08_loss.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Lovasz-Softmax and Jaccard hinge loss in PyTorch - Maxim Berman 2018 ESAT-PSI KU Leuven (MIT License).</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Lovasz-Loss">Lovasz Loss<a class="anchor-link" href="#Lovasz-Loss"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="lovasz_grad" class="doc_header"><code>lovasz_grad</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L31" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>lovasz_grad</code>(<strong><code>gt_sorted</code></strong>)</p>
</blockquote>
<p>Computes gradient of the Lovasz extension w.r.t sorted errors
See Alg. 1 in paper</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="iou_binary" class="doc_header"><code>iou_binary</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L46" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>iou_binary</code>(<strong><code>preds</code></strong>, <strong><code>labels</code></strong>, <strong><code>EMPTY</code></strong>=<em><code>1.0</code></em>, <strong><code>ignore</code></strong>=<em><code>None</code></em>, <strong><code>per_image</code></strong>=<em><code>True</code></em>)</p>
</blockquote>
<p>IoU for foreground class
binary: 1 foreground, 0 background</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="iou" class="doc_header"><code>iou</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L449" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>iou</code>(<strong><code>outputs</code></strong>:<code>Tensor</code>, <strong><code>targets</code></strong>:<code>Tensor</code>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-07</code></em>, <strong><code>threshold</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>activation</code></strong>:<code>str</code>=<em><code>'Sigmoid'</code></em>)</p>
</blockquote>
<p><a href="https://github.com/catalyst-team/catalyst/blob/master/catalyst/dl/utils/criterion/iou.py">https://github.com/catalyst-team/catalyst/blob/master/catalyst/dl/utils/criterion/iou.py</a>
Args:
    outputs (torch.Tensor): A list of predicted elements
    targets (torch.Tensor):  A list of elements that are to be predicted
    eps (float): epsilon to avoid zero division
    threshold (float): threshold for outputs binarization
    activation (str): An torch.nn activation applied to the outputs.
        Must be one of ["none", "Sigmoid", "Softmax2d"]
Returns:
    float: IoU (Jaccard) score</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Binary-losses">Binary losses<a class="anchor-link" href="#Binary-losses"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="lovasz_hinge" class="doc_header"><code>lovasz_hinge</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L88" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>lovasz_hinge</code>(<strong><code>logits</code></strong>, <strong><code>labels</code></strong>, <strong><code>per_image</code></strong>=<em><code>True</code></em>, <strong><code>ignore</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Binary Lovasz hinge loss
  logits: [B, H, W] Variable, logits at each pixel (between -\infty and +\infty)
  labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)
  per_image: compute the loss per image instead of per batch
  ignore: void class id</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="lovasz_hinge_flat" class="doc_header"><code>lovasz_hinge_flat</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L104" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>lovasz_hinge_flat</code>(<strong><code>logits</code></strong>, <strong><code>labels</code></strong>)</p>
</blockquote>
<p>Binary Lovasz hinge loss
  logits: [P] Variable, logits at each prediction (between -\infty and +\infty)
  labels: [P] Tensor, binary ground truth labels (0 or 1)
  ignore: label to ignore</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="flatten_binary_scores" class="doc_header"><code>flatten_binary_scores</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L124" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>flatten_binary_scores</code>(<strong><code>scores</code></strong>, <strong><code>labels</code></strong>, <strong><code>ignore</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Flattens predictions in the batch (binary case)
Remove labels equal to 'ignore'</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="StableBCELoss" class="doc_header"><code>class</code> <code>StableBCELoss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L139" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>StableBCELoss</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="binary_xloss" class="doc_header"><code>binary_xloss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L148" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>binary_xloss</code>(<strong><code>logits</code></strong>, <strong><code>labels</code></strong>, <strong><code>ignore</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Binary Cross entropy loss
  logits: [B, H, W] Variable, logits at each pixel (between -\infty and +\infty)
  labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)
  ignore: void class id</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Multiclass-losses">Multiclass losses<a class="anchor-link" href="#Multiclass-losses"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="lovasz_softmax" class="doc_header"><code>lovasz_softmax</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L160" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>lovasz_softmax</code>(<strong><code>probas</code></strong>, <strong><code>labels</code></strong>, <strong><code>classes</code></strong>=<em><code>'present'</code></em>, <strong><code>per_image</code></strong>=<em><code>False</code></em>, <strong><code>ignore</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Multi-class Lovasz-Softmax loss
  probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1).
          Interpreted as binary (sigmoid) output with outputs of size [B, H, W].
  labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)
  classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.
  per_image: compute the loss per image instead of per batch
  ignore: void class labels</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="lovasz_softmax_flat" class="doc_header"><code>lovasz_softmax_flat</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L178" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>lovasz_softmax_flat</code>(<strong><code>probas</code></strong>, <strong><code>labels</code></strong>, <strong><code>classes</code></strong>=<em><code>'present'</code></em>)</p>
</blockquote>
<p>Multi-class Lovasz-Softmax loss
  probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)
  labels: [P] Tensor, ground truth labels (between 0 and C - 1)
  classes: 'all' for all, 'present' for classes present in labels, or a list of classes to average.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="flatten_probas" class="doc_header"><code>flatten_probas</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L209" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>flatten_probas</code>(<strong><code>probas</code></strong>, <strong><code>labels</code></strong>, <strong><code>ignore</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Flattens predictions in the batch</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="xloss" class="doc_header"><code>xloss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L227" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>xloss</code>(<strong><code>logits</code></strong>, <strong><code>labels</code></strong>, <strong><code>ignore</code></strong>=<em><code>None</code></em>)</p>
</blockquote>
<p>Cross entropy loss</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Helper-functions">Helper functions<a class="anchor-link" href="#Helper-functions"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="isnan" class="doc_header"><code>isnan</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L234" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>isnan</code>(<strong><code>x</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="mean" class="doc_header"><code>mean</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L238" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>mean</code>(<strong><code>l</code></strong>, <strong><code>ignore_nan</code></strong>=<em><code>False</code></em>, <strong><code>empty</code></strong>=<em><code>0</code></em>)</p>
</blockquote>
<p>nanmean compatible with generators.</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="BCE-and-SoftDice-loss">BCE and SoftDice loss<a class="anchor-link" href="#BCE-and-SoftDice-loss"> </a></h2>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="bce_loss" class="doc_header"><code>bce_loss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L269" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>bce_loss</code>(<strong><code>output</code></strong>, <strong><code>target</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="SoftDiceLoss" class="doc_header"><code>class</code> <code>SoftDiceLoss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L273" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>SoftDiceLoss</code>() :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="DiceLoss" class="doc_header"><code>class</code> <code>DiceLoss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L289" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>DiceLoss</code>(<strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-07</code></em>, <strong><code>threshold</code></strong>:<code>float</code>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BCEDiceLoss" class="doc_header"><code>class</code> <code>BCEDiceLoss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L304" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BCEDiceLoss</code>(<strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-07</code></em>, <strong><code>threshold</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>bce_weight</code></strong>:<code>float</code>=<em><code>0.5</code></em>, <strong><code>dice_weight</code></strong>:<code>float</code>=<em><code>0.5</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="IoULoss" class="doc_header"><code>class</code> <code>IoULoss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L345" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>IoULoss</code>(<strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-07</code></em>, <strong><code>threshold</code></strong>:<code>float</code>=<em><code>None</code></em>) :: <code>Module</code></p>
</blockquote>
<p>Intersection over union (Jaccard) loss
Args:
    eps (float): epsilon to avoid zero division
    threshold (float): threshold for outputs binarization
    activation (str): An torch.nn activation applied to the outputs.
        Must be one of ['none', 'Sigmoid', 'Softmax2d']</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="BinaryFocalLoss" class="doc_header"><code>class</code> <code>BinaryFocalLoss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L368" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>BinaryFocalLoss</code>(<strong><code>alpha</code></strong>=<em><code>0.5</code></em>, <strong><code>gamma</code></strong>=<em><code>2</code></em>, <strong><code>ignore_index</code></strong>=<em><code>None</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>, <strong><code>reduced</code></strong>=<em><code>False</code></em>, <strong><code>threshold</code></strong>=<em><code>0.5</code></em>) :: <code>_Loss</code></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="FocalBCEDiceLoss" class="doc_header"><code>class</code> <code>FocalBCEDiceLoss</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L418" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>FocalBCEDiceLoss</code>(<strong><code>alpha</code></strong>=<em><code>0.5</code></em>, <strong><code>gamma</code></strong>=<em><code>2</code></em>, <strong><code>ignore_index</code></strong>=<em><code>None</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>, <strong><code>reduced</code></strong>=<em><code>False</code></em>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-07</code></em>, <strong><code>threshold</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>bce_weight</code></strong>:<code>float</code>=<em><code>0.5</code></em>, <strong><code>dice_weight</code></strong>:<code>float</code>=<em><code>0.5</code></em>) :: <a href="/steel_segmentation/loss.html#BCEDiceLoss"><code>BCEDiceLoss</code></a></p>
</blockquote>
<p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>

<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))

</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
                evaluation mode.
:vartype training: bool</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Utilities">Utilities<a class="anchor-link" href="#Utilities"> </a></h3>
</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="LabelSmoother" class="doc_header"><code>class</code> <code>LabelSmoother</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L436" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>LabelSmoother</code>(<strong><code>eps</code></strong>=<em><code>1e-08</code></em>)</p>
</blockquote>
<p>Maps binary labels (0, 1) to (eps, 1 - eps)</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="iou" class="doc_header"><code>iou</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L449" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>iou</code>(<strong><code>outputs</code></strong>:<code>Tensor</code>, <strong><code>targets</code></strong>:<code>Tensor</code>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-07</code></em>, <strong><code>threshold</code></strong>:<code>float</code>=<em><code>None</code></em>, <strong><code>activation</code></strong>:<code>str</code>=<em><code>'Sigmoid'</code></em>)</p>
</blockquote>
<p><a href="https://github.com/catalyst-team/catalyst/blob/master/catalyst/dl/utils/criterion/iou.py">https://github.com/catalyst-team/catalyst/blob/master/catalyst/dl/utils/criterion/iou.py</a>
Args:
    outputs (torch.Tensor): A list of predicted elements
    targets (torch.Tensor):  A list of elements that are to be predicted
    eps (float): epsilon to avoid zero division
    threshold (float): threshold for outputs binarization
    activation (str): An torch.nn activation applied to the outputs.
        Must be one of ["none", "Sigmoid", "Softmax2d"]
Returns:
    float: IoU (Jaccard) score</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="dice" class="doc_header"><code>dice</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L480" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>dice</code>(<strong><code>outputs</code></strong>:<code>Tensor</code>, <strong><code>targets</code></strong>:<code>Tensor</code>, <strong><code>eps</code></strong>:<code>float</code>=<em><code>1e-07</code></em>, <strong><code>threshold</code></strong>:<code>float</code>=<em><code>None</code></em>)</p>
</blockquote>
<p>Computes the dice metric
Args:
    outputs (list):  A list of predicted elements
    targets (list): A list of elements that are to be predicted
    eps (float): epsilon
    threshold (float): threshold for outputs binarization
Returns:
    double:  Dice score</p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h4 id="focal_loss_with_logits" class="doc_header"><code>focal_loss_with_logits</code><a href="https://github.com/marcomatteo/steel_segmentation/tree/master/steel_segmentation/loss.py#L508" class="source_link" style="float:right">[source]</a></h4><blockquote><p><code>focal_loss_with_logits</code>(<strong><code>input</code></strong>:<code>Tensor</code>, <strong><code>target</code></strong>:<code>Tensor</code>, <strong><code>gamma</code></strong>=<em><code>2.0</code></em>, <strong><code>alpha</code></strong>:<code>float</code>=<em><code>0.25</code></em>, <strong><code>reduction</code></strong>=<em><code>'mean'</code></em>, <strong><code>normalized</code></strong>=<em><code>False</code></em>, <strong><code>threshold</code></strong>:<code>float</code>=<em><code>None</code></em>)</p>
</blockquote>
<p><a href="https://github.com/BloodAxe/pytorch-toolbelt/blob/develop/pytorch_toolbelt/losses/functional.py">https://github.com/BloodAxe/pytorch-toolbelt/blob/develop/pytorch_toolbelt/losses/functional.py</a>
Compute binary focal loss between target and output logits.
See :class:<code>~pytorch_toolbelt.losses.FocalLoss</code> for details.
Args:
    input: Tensor of arbitrary shape
    target: Tensor of the same shape as input
    reduction (string, optional): Specifies the reduction to apply to the output:
        'none' | 'mean' | 'sum' | 'batchwise_mean'. 'none': no reduction will be applied,
        'mean': the sum of the output will be divided by the number of
        elements in the output, 'sum': the output will be summed. Note: :attr:<code>size_average</code>
        and :attr:<code>reduce</code> are in the process of being deprecated, and in the meantime,
        specifying either of those two args will override :attr:<code>reduction</code>.
        'batchwise_mean' computes mean loss per sample in batch. Default: 'mean'
    normalized (bool): Compute normalized focal loss (<a href="https://arxiv.org/pdf/1909.07829.pdf">https://arxiv.org/pdf/1909.07829.pdf</a>).
    threshold (float, optional): Compute reduced focal loss (<a href="https://arxiv.org/abs/1903.01347">https://arxiv.org/abs/1903.01347</a>).
References::
    <a href="https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/loss/losses.py">https://github.com/open-mmlab/mmdetection/blob/master/mmdet/core/loss/losses.py</a></p>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

</div>
 

