# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03_datasets.ipynb (unless otherwise specified).

__all__ = ['seed_everything', 'get_split_datasets', 'classes', 'ReadImagePathFromIndex', 'ReadRLEs', 'MakeMask',
           'ChannelMask', 'get_transforms', 'SteelDataset']

# Cell
from .metadata import *
from .masks import *

import torch
from fastcore.test import *
from fastai.vision.all import *

from collections import defaultdict, OrderedDict
from matplotlib import pyplot as plt
from sklearn.model_selection import StratifiedKFold, train_test_split

from PIL import Image
import pandas as pd
import numpy as np
import os
import cv2
import random

import albumentations as alb
from albumentations import pytorch as albpyt
from torch.utils.data import Dataset, sampler

# Cell
def seed_everything(seed=69):
    """
    Seeds `random`, `os.environ["PYTHONHASHSEED"]`,
    `numpy`, `torch.cuda` and `torch.backends`.
    """
    #warnings.filterwarnings("ignore")
    random.seed(seed)
    os.environ["PYTHONHASHSEED"] = str(seed)
    np.random.seed(seed)
#     torch.cuda.manual_seed(seed)
#     torch.backends.cudnn.deterministic = True

# Cell
def get_split_datasets(source:pd.DataFrame, x_tfms:Pipeline, y_tfms:Pipeline,
                 y_col:str="ClassId", nsplits=3, test_pct=0.2, kfolds=True):
    df = source
    n = len(df)
    split = train_test_split(range(n), test_size=test_pct)

    if not kfolds: return Datasets(df, [x_tfms, y_tfms], splits=split)

    dsets = OrderedDict()
    df_test = df.iloc[split[1]]
    df_train = df.iloc[split[0]]

    X = df_train.to_numpy()
    y = df_train[y_col].to_numpy()

    skf = StratifiedKFold(n_splits=nsplits, shuffle=True)
    for i, (train_index, valid_index) in enumerate(skf.split(X, y)):
        ksplit = [train_index, valid_index]
        dsets[i] = Datasets(df_train, [x_tfms, y_tfms], splits=ksplit)

    dsets[nsplits] = Datasets(df_test, [x_tfms, y_tfms])
    return dsets

# Cell
classes = [0, 1, 2, 3, 4]

# Cell
class ReadImagePathFromIndex(Transform):
    """Read RLEs from `train_pivot`"""
    def __init__(self, suff='', pref=train_path, label_delim=None):
        store_attr()
        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref

    def encodes(self, row:pd.Series, **kwargs):
        o = row.name # ImageId
        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o
        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'
        else: return o.split(self.label_delim) if len(o)>0 else []

# Cell
class ReadRLEs(Transform):
    """Read RLEs from `train_pivot`"""
    h, w = (256, 1600)

    def __init__(self, cols=2):
        self.cols = L(cols)
        self.c = len(self.cols)

    def encodes(self, row:pd.Series, **kwargs):
        if self.c == 1:
            rles = [''] * 4 # 4:class 1～4 (ch:0～3)
            rles[row["ClassId"]-1] = row["EncodedPixels"]
            return rles

        return [row[i] if not row[i] is np.nan else ''
                for i in self.cols]

# Cell
class MakeMask(Transform):
    """Read RLEs list and return a np.array"""
    h, w = (256, 1600)

    def __init__(self, flatten=True):
        self.flatten = flatten

    def encodes(self, o:list, **kwargs):
        mask = np.zeros((self.h, self.w, 4), dtype=np.float32) # 4:class 1～4 (ch:0～3)

        for i in range(4):
            rle = o[i]
            if rle is not '':
                mask[:, :, i] = rle2mask(rle=rle, value=1, shape=(self.h,self.w))

        if self.flatten:
            classes = np.array(range(1,5))
            return (mask * classes).sum(-1)

        return mask

    def decodes(self, mask, **kwargs):
        mask = (mask * np.array(range(1,5))).sum(-1) if len(mask.shape) == 3 else mask
        return [mask2rle(np.where(mask==c, mask, 0)) for c in range(1,5)]

# Cell
class ChannelMask(Transform):
    """Prepare Mask to 4-channel models"""
    order=9

    def create_mask(self, mask):
        new_mask = torch.zeros(4, mask.shape[0], mask.shape[1])
        for i in range(4):
            new_mask[i] = torch.where(mask==(i+1), 1, 0)
        return new_mask

    def decode_mask(self, mask, classes):
        return (mask * classes).sum(0)

    def encodes(self, o:TensorMask):
        if o.dim() == 2: return self.create_mask(o)
        elif o.dim() == 3:
            new_batch = []
            for mask in o: new_batch.append(self.create_mask(mask))
            return torch.stack(new_batch, axis=0)
        else: return o

    def decodes(self, o:TensorMask):
        classes = torch.tensor(range(1,5)).unsqueeze(-1).unsqueeze(-1)
        if o.dim() == 3: return self.decode_mask(o, classes)
        elif o.dim() == 4:
            new_masks = []
            for mask in o:
                new_masks.append(self.decode_mask(mask, classes))
            return torch.stack(new_masks, axis=0)
        else: return o

# Cell
def get_transforms(phase, mean, std):
    list_transforms = []
    if phase == "train":
        list_transforms.extend(
            [
                alb.HorizontalFlip(p=0.5),  # only horizontal flip for now
            ]
        )
    list_transforms.extend(
        [
            alb.Normalize(mean=mean, std=std, p=1),
            albpyt.ToTensor(),
        ]
    )
    list_trfms = alb.Compose(list_transforms)
    return list_trfms

# Cell
class SteelDataset(Dataset):

    def __init__(self, df, mean, std, phase):
        self.df = df
        self.mean = mean
        self.std = std
        self.phase = phase
        self.transforms = get_transforms(phase, mean, std)
        self.fnames = self.df.index.tolist()

    def __getitem__(self, idx):
        image_id, mask = make_mask(idx, df=self.df)
        image_path = train_path / image_id
        img = cv2.imread(str(image_path))
        augmented = self.transforms(image=img, mask=mask)
        img = augmented['image']
        mask = augmented['mask']         # 1x256x1600x4
        mask = mask[0].permute(2, 0, 1)  # 4x256x1600
        return img, mask

    def __len__(self):
        return len(self.fnames)