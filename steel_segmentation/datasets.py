# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/03_datasets.ipynb (unless otherwise specified).

__all__ = ['classes', 'ReadImagePathFromIndex', 'ReadRLEs', 'MakeMask', 'ChannelMask', 'get_transforms', 'SteelDataset']

# Cell
from .metadata import *
from .masks import *

from fastcore.test import *
from fastai.vision.all import *
from collections import defaultdict
from matplotlib import pyplot as plt
from sklearn.model_selection import StratifiedKFold, train_test_split

from PIL import Image
import pandas as pd
import numpy as np
import os
import cv2

from torch.utils.data import Dataset, sampler
from albumentations import (
    HorizontalFlip, ShiftScaleRotate, Resize, Compose, GaussNoise)
from albumentations.pytorch import ToTensor
import albumentations as alb

# Cell
classes = [0, 1, 2, 3, 4]

# Cell
class ReadImagePathFromIndex(Transform):
    """Read RLEs from `train_pivot`"""
    def __init__(self, suff='', pref=train_path, label_delim=None):
        store_attr()
        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref

    def encodes(self, row:pd.Series, **kwargs):
        o = row.name # ImageId
        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o
        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'
        else: return o.split(self.label_delim) if len(o)>0 else []

# Cell
class ReadRLEs(Transform):
    """Read RLEs from `train_pivot`"""
    h, w = (256, 1600)

    def __init__(self, cols=2):
        self.cols = L(cols)
        self.c = len(self.cols)

    def encodes(self, row:pd.Series, **kwargs):
        if self.c == 1:
            rles = [''] * 4 # 4:class 1～4 (ch:0～3)
            rles[row["ClassId"]-1] = row["EncodedPixels"]
            return rles

        return [row[i] if not row[i] is np.nan else ''
                for i in self.cols]

# Cell
class MakeMask(Transform):
    """Read RLEs list and return a np.array"""
    h, w = (256, 1600)

    def __init__(self, flatten=True):
        self.flatten = flatten

    def encodes(self, o:list, **kwargs):
        mask = np.zeros((self.h, self.w, 4), dtype=np.float32) # 4:class 1～4 (ch:0～3)

        for i in range(4):
            rle = o[i]
            if rle is not '':
                mask[:, :, i] = rle2mask(rle=rle, value=1, shape=(self.h,self.w))

        if self.flatten:
            classes = np.array(range(1,5))
            return (mask * classes).sum(-1)

        return mask

    def decodes(self, mask, **kwargs):
        mask = (mask * np.array(range(1,5))).sum(-1) if len(mask.shape) == 3 else mask
        return [mask2rle(np.where(mask==c, mask, 0)) for c in range(1,5)]

# Cell
class ChannelMask(Transform):
    """Prepare Mask to 4-channel models"""
    order=9
    def encodes(self, o:TensorMask):
        new_masks = []
        for mask in o:
            new_mask = torch.zeros(4, mask.shape[0], mask.shape[1])
            for i in range(4):
                new_mask[i] = torch.where(mask==(i+1), 1, 0)
            new_masks.append(new_mask)

        return torch.stack(new_masks, axis=0)

    def decodes(self, o:TensorMask):
        classes = torch.tensor(range(1,5)).unsqueeze(-1).unsqueeze(-1)
        new_masks = []
        for mask in o:
            new_masks.append((mask * classes).sum(0))
        return torch.stack(new_masks, axis=0)

# Cell
def get_transforms(phase, mean, std):
    list_transforms = []
    if phase == "train":
        list_transforms.extend(
            [
                HorizontalFlip(p=0.5),  # only horizontal flip for now
            ]
        )
    list_transforms.extend(
        [
            alb.Normalize(mean=mean, std=std, p=1),
            ToTensor(),
        ]
    )
    list_trfms = Compose(list_transforms)
    return list_trfms

# Cell
class SteelDataset(Dataset):

    def __init__(self, df, mean, std, phase):
        self.df = df
        self.mean = mean
        self.std = std
        self.phase = phase
        self.transforms = get_transforms(phase, mean, std)
        self.fnames = self.df.index.tolist()

    def __getitem__(self, idx):
        image_id, mask = make_mask(idx, df=self.df)
        image_path = train_path / image_id
        img = cv2.imread(str(image_path))
        augmented = self.transforms(image=img, mask=mask)
        img = augmented['image']
        mask = augmented['mask']         # 1x256x1600x4
        mask = mask[0].permute(2, 0, 1)  # 4x256x1600
        return img, mask

    def __len__(self):
        return len(self.fnames)