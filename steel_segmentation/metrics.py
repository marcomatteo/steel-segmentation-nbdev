# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_metrics.ipynb (unless otherwise specified).

__all__ = ['ModDiceMulti', 'single_dice_coef', 'single_dice_coef_channel', 'SingleDiceCoefChannel', 'SingleDiceCoef',
           'dices', 'Dices', 'epoch_log']

# Cell
from .metadata import *
from .masks import *
from .datasets import *
from .dataloaders import *

import fastai
from fastai.vision.all import *
from fastcore.foundation import *

import torch
import torch.nn.functional as F

import segmentation_models_pytorch as smp

# Cell
class ModDiceMulti(Metric):
    "Averaged Dice metric (Macro F1) for multiclass target in segmentation"

    def __init__(self, axis=1, with_logits=False):
        self.axis = axis
        self.with_logits = with_logits

    def reset(self): self.inter, self.union = {}, {}

    def accumulate(self, learn):
        if self.with_logits:
            logit = learn.pred
            prob = torch.sigmoid(logit)
            pred = (prob > 0.5).float().argmax(dim=self.axis)
        else:
            pred = learn.pred.argmax(dim=self.axis)

        y = learn.yb[0]
        # Added to deal with 4-channels masks
        if pred.shape != y.shape:
            y = y.argmax(dim=self.axis)

        pred, targ = flatten_check(pred, y)
        for c in range(learn.pred.shape[self.axis]):
            p = torch.where(pred == c, 1, 0)
            t = torch.where(targ == c, 1, 0)
            p, t = TensorBase(p), TensorBase(t) # may be redundant (old fastai bug)
            c_inter = (p*t).float().sum().item()
            c_union = (p+t).float().sum().item()
            if c in self.inter:
                self.inter[c] += c_inter
                self.union[c] += c_union
            else:
                self.inter[c] = c_inter
                self.union[c] = c_union

    @property
    def value(self):
        binary_dice_scores = np.array([])
        for c in self.inter:
            binary_dice_scores = np.append(
                binary_dice_scores,
                2.*self.inter[c]/self.union[c] if self.union[c] > 0 else np.nan)
        self.binary_dice_scores = binary_dice_scores
        return np.nanmean(binary_dice_scores)

# Cell
def single_dice_coef(y_true, y_pred, smooth=1):
    """Binary segmentation function."""
    y_true_f = np.ndarray.flatten(y_true)
    y_pred_f = np.ndarray.flatten(y_pred)
    intersection = np.sum(y_true_f * y_pred_f)
    return (2. * intersection + smooth) / (np.sum(y_true_f) + np.sum(y_pred_f) + smooth)

def single_dice_coef_channel(y_true, y_pred, smooth=1):
    """Multichannel segmentation function."""
    ch1 = single_dice_coef(y_true[:,0,:,:], y_pred[:,0,:,:],smooth)
    ch2 = single_dice_coef(y_true[:,1,:,:], y_pred[:,1,:,:],smooth)
    ch3 = single_dice_coef(y_true[:,2,:,:], y_pred[:,2,:,:],smooth)
    ch4 = single_dice_coef(y_true[:,3,:,:], y_pred[:,3,:,:],smooth)
    res = (ch1+ch2+ch3+ch4)/4
    return res

# Cell
SingleDiceCoefChannel = AccumMetric(single_dice_coef_channel, to_np=True, flatten=False, sigmoid=True, thresh=0.5)

# Cell
SingleDiceCoef = AccumMetric(single_dice_coef, to_np=True, flatten=False)

# Cell
def dices(probability, truth, threshold=0.5):
    """
    Calculates dice of positive and negative images seperately
    `probability` and `truth` must be `torch.Tensors`.
    """
    probability = torch.sigmoid(probability) if probability.max()>1 & probability.min<0 else probability
    base_dice_scores, dice_pos_scores, dice_neg_scores = [], [], []
    probability, truth = TensorBase(probability), TensorBase(truth)
    batch_size = len(truth)
    with torch.no_grad():
        probability = probability.view(batch_size, -1)
        truth = truth.view(batch_size, -1)
        assert(probability.shape == truth.shape)

        p = (probability > threshold).float()
        t = (truth > 0.5).float()

        t_sum = t.sum(-1)
        p_sum = p.sum(-1)
        neg_index = torch.nonzero(t_sum == 0)
        pos_index = torch.nonzero(t_sum >= 1)

        dice_neg = (p_sum == 0).float()
        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))

        dice_neg = dice_neg[neg_index]
        dice_pos = dice_pos[pos_index]
        dice = torch.cat([dice_pos, dice_neg])

        base_dice_scores.extend(dice.tolist())
        dice_pos_scores.extend(dice_pos.tolist())
        dice_neg_scores.extend(dice_neg.tolist())

        dice     = np.nanmean(base_dice_scores)
        dice_neg = np.nanmean(dice_neg_scores)
        dice_pos = np.nanmean(dice_pos_scores)

    return dice, dice_neg, dice_pos

# Cell
Dices = AccumMetric(dices, flatten=False, dim_argmax=0)

# Cell
def epoch_log(epoch_loss, dices):
    """logging the metrics at the end of an epoch"""
    dice, dice_neg, dice_pos = dices
    print(f"Loss: {epoch_loss:.4f} | dice: {dice:.4f} | dice_neg: {dice_neg:.4f} | dice_pos: {dice_pos:.4f}")
    return dice