# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/05_metrics.ipynb (unless otherwise specified).

__all__ = ['ModDiceMulti', 'KaggleDice', 'dice_kaggle', 'metric', 'epoch_log']

# Cell
from .metadata import *
from .masks import *
from .datasets import *
from .dataloaders import *

import fastai
from fastai.vision.all import *
from fastcore.foundation import *

import torch
import torch.nn.functional as F

import segmentation_models_pytorch as smp

# Cell
class ModDiceMulti(Metric):
    "Averaged Dice metric (Macro F1) for multiclass target in segmentation"

    def __init__(self, axis=1): self.axis = axis
    def reset(self): self.inter, self.union = {}, {}

    def accumulate(self, learn):
        pred = learn.pred.argmax(dim=self.axis)
        y = learn.yb[0]

        # Added to deal with 4-channels masks
        if pred.shape != y.shape:
            y = y.argmax(dim=self.axis)

        pred, targ = flatten_check(pred, y)
        for c in range(learn.pred.shape[self.axis]):
            p = torch.where(pred == c, 1, 0)
            t = torch.where(targ == c, 1, 0)
            p, t = TensorBase(p), TensorBase(t)
            c_inter = (p*t).float().sum().item()
            c_union = (p+t).float().sum().item()
            if c in self.inter:
                self.inter[c] += c_inter
                self.union[c] += c_union
            else:
                self.inter[c] = c_inter
                self.union[c] = c_union

    @property
    def value(self):
        binary_dice_scores = np.array([])
        for c in self.inter:
            binary_dice_scores = np.append(
                binary_dice_scores,
                2.*self.inter[c]/self.union[c] if self.union[c] > 0 else np.nan)
        self.binary_dice_scores = binary_dice_scores
        return np.nanmean(binary_dice_scores)

# Cell
class KaggleDice(Metric):
    """
    Multi-class Dice used in Severstal comp,
    is 1 when prediction and mask are empty
    """
    def __init__(self, axis=1, eps=1e-9): self.axis, self.eps = axis, eps
    def reset(self): self.inter, self.union = {}, {}

    def accumulate(self, learn):
        y = learn.yb[0]
        preds = learn.pred

        if preds.shape == y.shape:
            y = y.argmax(dim=self.axis)

        n, c = y.shape[0], preds.shape[self.axis]

        preds = preds.argmax(dim=self.axis).view(n, -1)
        targs = y.view(n, -1)

#         pred, targ = flatten_check(preds, targs)
        for i in range(0, c):
            p = torch.where(preds == i, 1, 0)
            t = torch.where(targs == i, 1, 0)

            p, t = TensorBase(p), TensorBase(t)

            c_inter = (p*t).sum(-1).float().cpu()#.item()
            c_union = (p+t).sum(-1).float().cpu()#.item()
            if i in self.inter:
                self.inter[i] = torch.cat([self.inter[i], c_inter], dim=0)
                self.union[i] = torch.cat([self.union[i], c_union], dim=0)
            else:
                self.inter[i] = c_inter
                self.union[i] = c_union

    @property
    def value(self):
        binary_dice_scores = np.array([])
        for c in range(len(self.inter)):
            cond = self.union[c] == 0
            val = 2.*(self.inter[c]+self.eps)/(self.union[c]+self.eps)
            val[cond] = 1
            binary_dice_scores = np.append(binary_dice_scores, val.numpy())
        self.binary_dice_scores = binary_dice_scores
        return np.nanmean(binary_dice_scores)

# Cell
def dice_kaggle(pred: Tensor, targ: Tensor, iou:bool=False, eps:float=1e-8):
    """
    The metric of the competition,
    if there's no defect in `targ` and no defects in `pred`: dice=1.
    """
    n, c = targ.shape[0], pred.shape[1]

    if pred.shape == targ.shape:
        targ = targ.argmax(dim=1)

    pred = pred.argmax(dim=1).view(n, -1)
    targ = targ.view(n, -1)

    intersect_list, union_list = [], []
    for i in range(c):
        inp, trgs = TensorBase(pred), TensorBase(targ)

        inter = ((inp == i) & (trgs == i)).sum(-1).float()
        un = ((inp == i).sum(-1) + (trgs == i).sum(-1))

        intersect_list.append(inter)
        union_list.append(un)

    intersect = torch.stack(intersect_list)
    union = torch.stack(union_list)

    if not iou:
        metric = ((2.0 * intersect + eps) / (union + eps))
    else:
        metric = ((intersect + eps) / (union - intersect + eps))

    return metric.mean()

# Cell
def metric(probability, truth, threshold=0.5):
    """
    Calculates dice of positive and negative images seperately
    `probability` and `truth` must be `torch.Tensors`.
    """
    #if isinstance(truth, tuple):
    #    truth = truth[0]
    base_dice_scores, dice_pos_scores, dice_neg_scores = [], [], []

    batch_size = len(truth)
    with torch.no_grad():
        probability = probability.view(batch_size, -1)
        truth = truth.view(batch_size, -1)
        assert(probability.shape == truth.shape)

        p = (probability > threshold).float()
        t = (truth > 0.5).float()

        t_sum = t.sum(-1)
        p_sum = p.sum(-1)
        neg_index = torch.nonzero(t_sum == 0)
        pos_index = torch.nonzero(t_sum >= 1)

        dice_neg = (p_sum == 0).float()
        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1))

        dice_neg = dice_neg[neg_index]
        dice_pos = dice_pos[pos_index]
        dice = torch.cat([dice_pos, dice_neg])

        base_dice_scores.extend(dice.tolist())
        dice_pos_scores.extend(dice_pos.tolist())
        dice_neg_scores.extend(dice_neg.tolist())

        dice     = np.nanmean(base_dice_scores)
        dice_neg = np.nanmean(dice_neg_scores)
        dice_pos = np.nanmean(dice_pos_scores)

    return dice, dice_neg, dice_pos

# Cell
def epoch_log(epoch_loss, meter):
    """logging the metrics at the end of an epoch"""
    dices = meter.get_metrics()
    dice, dice_neg, dice_pos = dices
    print(f"Loss: {epoch_loss:.4f} | dice: {dice:.4f} | dice_neg: {dice_neg:.4f} | dice_pos: {dice_pos:.4f}")
    return dice